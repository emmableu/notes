"use strict";(globalThis.webpackChunknotes=globalThis.webpackChunknotes||[]).push([[50427],{25328:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"Zero To Hero/Makemore 5 - WaveNet","title":"Makemore 5 - WaveNet","description":"We take the 2-layer MLP from previous video and make it deeper with a tree-like structure, arriving at a convolutional neural network architecture similar to the WaveNet (2016) from DeepMind. In the WaveNet paper, the same hierarchical architecture is implemented more efficiently using causal dilated convolutions (not yet covered). Along the way we get a better sense of torch.nn and what it is and how it works under the hood, and what a typical deep learning development process looks like (a lot of reading of documentation, keeping track of multidimensional tensor shapes, moving between jupyter notebooks and repository code, ...).","source":"@site/docs/04. Zero To Hero/07. Makemore 5 - WaveNet.md","sourceDirName":"04. Zero To Hero","slug":"/p/f6874608-fc80-4c3b-98aa-4ac3eb261e37","permalink":"/notes/docs/p/f6874608-fc80-4c3b-98aa-4ac3eb261e37","draft":false,"unlisted":false,"editUrl":"https://github.com/emmableu/notes/edit/main/docs/04. Zero To Hero/07. Makemore 5 - WaveNet.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"created_at":"2025-11-02","page_link":"/p/f6874608-fc80-4c3b-98aa-4ac3eb261e37","slug":"/p/f6874608-fc80-4c3b-98aa-4ac3eb261e37"},"sidebar":"tutorialSidebar","previous":{"title":"5. Makemore 4 - Backpropagation Ninja","permalink":"/notes/docs/p/b52964bd-d3bf-4f0c-bce8-750a995dfb2f"},"next":{"title":"Let\u2019s Build GPT","permalink":"/notes/docs/p/8c0b35bd-57b9-4149-b6fe-f6a60b69e248"}}');var o=t(74848),r=t(28453);const i={created_at:"2025-11-02",page_link:"/p/f6874608-fc80-4c3b-98aa-4ac3eb261e37",slug:"/p/f6874608-fc80-4c3b-98aa-4ac3eb261e37"},s="1. Step 1: Refactor the MLP code from Makemore 3 using the nn.Sequential and nn.Flatten",d={},l=[{value:"Step 2.1: Adjust input to allow block_size = 8",id:"step-21-adjust-input-to-allow-block_size--8",level:2},{value:"Step 2.2, Update Network Structure",id:"step-22-update-network-structure",level:2},{value:"Step 2.2.1: Add FlattenConsecutive Layer",id:"step-221-add-flattenconsecutive-layer",level:3},{value:"Step 2.2.2: Adjust the BatchNorm Dimension",id:"step-222-adjust-the-batchnorm-dimension",level:3},{value:"2.3 Add Forward Hook to Print Layer Shape",id:"23-add-forward-hook-to-print-layer-shape",level:2}];function c(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"We take the 2-layer MLP from previous video and make it deeper with a tree-like structure, arriving at a convolutional neural network architecture similar to the WaveNet (2016) from DeepMind. In the WaveNet paper, the same hierarchical architecture is implemented more efficiently using causal dilated convolutions (not yet covered). Along the way we get a better sense of torch.nn and what it is and how it works under the hood, and what a typical deep learning development process looks like (a lot of reading of documentation, keeping track of multidimensional tensor shapes, moving between jupyter notebooks and repository code, ...)."}),"\n",(0,o.jsx)(n.p,{children:"Links:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["makemore on github: ",(0,o.jsx)(n.a,{href:"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbThDX0luOEtJSlE5RC1TN2FJRlhtUk1uUVZtZ3xBQ3Jtc0tudDAtZDZHblpHOWVTQVhhRkdmWDI2RWp2eGE1UG5jcDhjb2NYM0lmeXpPTmtjWmVuT3pWN1dRcHdEQWM4NmhnS1Nub3RsWGt6NjhyeGtiZFNYRFpzQnNjbjUyRE1ZTG1Gck82RDFDdWRjYUpDVWhFNA&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fmakemore&v=t3YJ5hKiMQ0",children:"https://github.com/karpathy/makemore"})]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["jupyter notebook I built in this video: ",(0,o.jsx)(n.a,{href:"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbmVzRkhTM2NDS0ZDR2NiTkIwOGRXemt2R1I0UXxBQ3Jtc0ttNVJaUFQ0TVc5RllYanRtRzFnZ0lEakZoZnRmVWQxdWp5U0RZN25MWURCM050NzBEZUpGczJPSzVjWVY1Zk5tWjc1b3N5YlhRZ3hKRnlnakU5Sjg3TEVUd18wMGFRaWVFbHB5Vkh4YnJLYWdmRlQzbw&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fnn-zero-to-hero%2Fblob%2Fmaster%2Flectures%2Fmakemore%2Fmakemore_part5_cnn1.ipynb&v=t3YJ5hKiMQ0",children:"https://github.com/karpathy/nn-zero-t..."})]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["collab notebook: ",(0,o.jsx)(n.a,{href:"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbG9JcTlQVlFVX1huRkFzVHBPTjlGUzBHeTdHd3xBQ3Jtc0ttNE91S0FkajJsckZyOWswbTZ0ME5qd1N2MnNlcW9fVUNnQm5ndGhsZGFJUndGREIwS2FqZUtzYndkMHktOHh0TnprWkctVHA2RHJhc2xrUTlkWkVWdTZYbFNhRGVaYjdPeEtuaDlOWDd6cXdOMjFvcw&q=https%3A%2F%2Fcolab.research.google.com%2Fdrive%2F1CXVEmCO_7r7WYZGb5qnjfyxTvQa13g5X%3Fusp%3Dsharing&v=t3YJ5hKiMQ0",children:"https://colab.research.google.com/dri..."})]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Supplementary links:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["WaveNet 2016 from DeepMind ",(0,o.jsx)(n.a,{href:"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbm5VemlRazRSdWNKLXhGdThYUXQxZDBkUktFZ3xBQ3Jtc0ttV2pPTHZqcE9XbDNKbndMT1ZYT2cyU0tzTTd4bGdmZUZneENFOUFEUVVoLU5YbmhyOUJTSjJmRThGLW50Uk1TMmN2VGZPc0ZSc3hNN0xWTlRnb19hd0JEcTBlRjVxRnlxS1NQU1h5T3RSSnVxX3FjMA&q=https%3A%2F%2Farxiv.org%2Fabs%2F1609.03499&v=t3YJ5hKiMQ0",children:"https://arxiv.org/abs/1609.03499"})]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Bengio et al. 2003 MLP LM ",(0,o.jsx)(n.a,{href:"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa0VKVmdPaXJGR3l6Ui11OG80NURQRWpkQlNyQXxBQ3Jtc0trVTk0MS1hd0JOVUdiXzB0ZGtvWW1TTm9od2FkdEVyRUNoY0sxY2szcDByRkJsYlpaVTdCTjVJNi14b0RVVVdxcUp2WjFfRVphbDlldmhMekhZSjhhSWtiakpOaVp5UlB0YmpibjhndWZiX2UxbFhmSQ&q=https%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fbengio03a%2Fbengio03a.pdf&v=t3YJ5hKiMQ0",children:"https://www.jmlr.org/papers/volume3/b..."})]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"1-step-1-refactor-the-mlp-code-from-makemore-3-using-the-nnsequential-and-nnflatten",children:"1. Step 1: Refactor the MLP code from Makemore 3 using the nn.Sequential and nn.Flatten"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport random\nfrom torch import nn\n\nwords = open('makemore-master/names.txt', 'r').read().splitlines()\nwords = words\n\n# build the vocabulary of characters and mappings to/from integers\nchars = sorted(list(set(''.join(words))))\nstoi = {s: i + 1 for i, s in enumerate(chars)}\nstoi['.'] = 0\nitos = {i: s for s, i in stoi.items()}\nvocab_size = len(itos)\nprint(itos)\nprint(vocab_size)\n\n# build the dataset\nblock_size = 3  # context length: how many characters do we take to predict the next one?\n\ndef build_dataset(words):\n    X, Y = [], []\n\n    for w in words:\n        w = '...' + w + \".\"\n        for c1, c2, c3, c4 in zip(w, w[1:], w[2:], w[3:]):\n            X.append([stoi[ele] for ele in [c1,c2,c3]])\n            Y.append(stoi[c4])\n    X = torch.tensor(X)\n    Y = torch.tensor(Y)\n    print(X.shape, Y.shape)\n    return X, Y\n\nrandom.seed(42)\nrandom.shuffle(words)\nn1 = int(0.8 * len(words))\nn2 = int(0.9 * len(words))\n\nXtr, Ytr = build_dataset(words[:n1])  # 80%\nXdev, Ydev = build_dataset(words[n1:n2])  # 10%\nXte, Yte = build_dataset(words[n2:])  # 10%s\n\n# MLP revisited\nembd_dim = 10  # the dimensionality of the character embedding vectors\nn_hidden = 200  # the number of neurons in the hidden layer of the MLP\n\ndef build_network():\n    model = nn.Sequential(\n        nn.Embedding(num_embeddings=vocab_size, embedding_dim=embd_dim),\n        nn.Flatten(),\n\n        nn.Linear(in_features=block_size * embd_dim, out_features=n_hidden, bias=False),\n        nn.BatchNorm1d(num_features=n_hidden, momentum=0.001),\n        nn.Tanh(),\n\n        nn.Linear(in_features=n_hidden, out_features=vocab_size, bias=False),\n        nn.BatchNorm1d(num_features=vocab_size, momentum=0.001),\n    )\n    model[-1].weight.data *= 0.1 # make the last layer less confident\n    for p in model.parameters():\n        p.requires_grad = True\n    return model\n\nbuild_network()\n\nloss_fn = nn.CrossEntropyLoss()\nNUM_EPOCHS = 2\nstep_size = 0.1\n\ndef train(X, Y):\n    model = build_network()\n    lossi = []\n    dataset = torch.utils.data.TensorDataset(X, Y)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, drop_last=True) #use drop_last = true to avoid one sample batch\n    for i in range(NUM_EPOCHS):\n        for j, (train_x, train_y) in enumerate(dataloader):\n            for p in model.parameters():\n                p.grad = None\n            y_pred = model.forward(train_x)\n            loss = loss_fn(y_pred, train_y)\n            if j == len(dataloader) - 1 or j % 1000 == 0:\n                print(f\"Epoch {i:3d}/{NUM_EPOCHS-1:3d}, Batch {j:4d}/{len(dataloader)-1:4d}, loss={loss.item():.4f}\")\n            loss.backward()\n            lossi.append(loss.log10().item())\n            for p in model.parameters():\n                p.data -= step_size * p.grad\n    plt.plot(lossi)\n    plt.show()\n    return model\n\ng = torch.Generator().manual_seed(42)\ndef generate():\n    model = train(Xtr, Ytr)\n    word_lst = []\n    model.eval()\n    with torch.no_grad():\n        for _ in range(100):\n            xi = torch.zeros(1, 3, dtype=torch.int32)\n            cur_word = []\n            y = '[INIT]'\n            while y != \".\":\n                y_prob = xi\n                y_prob = model.forward(y_prob)\n                y_prob = y_prob.softmax(dim=-1)\n                iy = torch.multinomial(y_prob, num_samples=1, generator=g).item()\n                y = itos[iy]\n                xi = torch.tensor([xi[0, 1:].tolist() + [iy]], dtype=torch.int32)\n                cur_word.append(y)\n            word_lst.append(\"\".join(cur_word))\n\n    print(word_lst)\n\ngenerate()\n"})}),"\n",(0,o.jsx)(n.p,{children:"output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"Epoch   0/  1, Batch    0/1825, loss=3.2999\nEpoch   0/  1, Batch 1000/1825, loss=2.2749\nEpoch   0/  1, Batch 1825/1825, loss=2.2904\nEpoch   1/  1, Batch    0/1825, loss=2.3452\nEpoch   1/  1, Batch 1000/1825, loss=2.1585\nEpoch   1/  1, Batch 1825/1825, loss=2.2466\n['anuseen.', 'kis.', 'marian.', 'dan.', 'shan.', 'silaylen.', 'kemarie.', 'kan.', 'epiacholen.', 'dazi.', 'kend.',... ]\n"})}),"\n",(0,o.jsx)(n.h1,{id:"step-2-get-the-train-and-validation-loss",children:"Step 2: Get the Train and Validation Loss"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def calc_loss(model, X, Y):\n    y_logits = model.forward(X)\n    y_prob = y_logits.softmax(dim=-1)\n    loss = loss_fn(y_prob, Y)\n    return loss.item()\n\nmodel = train(Xtr, Ytr)\nprint("Train Loss: ", calc_loss(model, Xtr, Ytr))\nprint("Validation Loss: ", calc_loss(model, Xdev, Ydev))\n'})}),"\n",(0,o.jsx)(n.p,{children:"output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"Train Loss:  3.1517810821533203\nValidation Loss:  3.152433156967163\n"})}),"\n",(0,o.jsx)(n.h1,{id:"step-3-update-network-structure-to-follow-the-wavenet-structure",children:"Step 3: Update network structure to follow the WaveNet structure:"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/202507042318495.png",alt:""})}),"\n",(0,o.jsx)(n.p,{children:"example:"}),"\n",(0,o.jsx)(n.p,{children:"input name:"}),"\n",(0,o.jsx)(n.p,{children:"\u201cemma\u201d"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"   X                         Y\t\t\n.......e                     m\n......em                     m\n.....emm                     a\n....emma                     .\n"})}),"\n",(0,o.jsx)(n.p,{children:"layer dimension info:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"embd_dim = 10  # the dimensionality of the character embedding vectors\nn_hidden = 200  # the number of neurons in the hidden layer of the MLP\n"})}),"\n",(0,o.jsx)(n.p,{children:"Layers:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"input"}),"\n",(0,o.jsx)(n.li,{children:"embedding"}),"\n",(0,o.jsxs)(n.li,{children:["flatten_consecutive that concat 2 chars/input element\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"linear, batchnorm, tanh"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["flatten_consecutive that concat 2 chars/input element\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"linear, batchnorm, tanh"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["flatten_consecutive that concat 2 chars/input element\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"linear, batchnorm, tanh"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Adding the shape to the above layer information:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"input 4 * 8"}),"\n",(0,o.jsx)(n.li,{children:"embedding 4 * 8 * 10"}),"\n",(0,o.jsxs)(n.li,{children:["flatten_consecutive that concat 2 chars/input element 4 * 4 * 20\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"linear, 4 * 4 * 200"}),"\n",(0,o.jsx)(n.li,{children:"batchnorm, tanh 4 * 4 * 200"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["flatten_consecutive that concat 2 chars/input element 4 * 2 * 400\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"linear, 4 * 2 * 200"}),"\n",(0,o.jsx)(n.li,{children:"batchnorm, tanh 4 * 2 * 200"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["flatten_consecutive that concat 2 chars/input element 4 * 1 * 400 \u21d2 4 * 400\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"linear,  4 * 27"}),"\n",(0,o.jsx)(n.li,{children:"batchnorm 4 * 27"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"step-21-adjust-input-to-allow-block_size--8",children:"Step 2.1: Adjust input to allow block_size = 8"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"block_size = 8  # context length: how many characters do we take to predict the next one?\n\ndef build_dataset(words):\n    X, Y = [], []\n\n    for w in words:\n        w = '.' * (block_size - 1) + w + \".\"\n        zip_data = []\n        for i in range(block_size):\n            zip_data.append(w[i:])\n        zip_data.append(w[block_size:])\n        for data in zip(*zip_data):\n            X.append([stoi[ele] for ele in data[:-1]])\n            Y.append(stoi[data[-1]])\n    X = torch.tensor(X)\n    Y = torch.tensor(Y)\n    print(X.shape, Y.shape)\n    return X, Y\n\nrandom.seed(42)\nrandom.shuffle(words)\nn1 = int(0.8 * len(words))\nn2 = int(0.9 * len(words))\n\nXtr, Ytr = build_dataset(words[:n1])  # 80%\nXdev, Ydev = build_dataset(words[n1:n2])  # 10%\nXte, Yte = build_dataset(words[n2:])  # 10%s\n"})}),"\n",(0,o.jsx)(n.p,{children:"output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n27\ntorch.Size([156999, 8]) torch.Size([156999])\ntorch.Size([19452, 8]) torch.Size([19452])\ntorch.Size([19662, 8]) torch.Size([19662])\n"})}),"\n",(0,o.jsx)(n.h2,{id:"step-22-update-network-structure",children:"Step 2.2, Update Network Structure"}),"\n",(0,o.jsx)(n.h3,{id:"step-221-add-flattenconsecutive-layer",children:"Step 2.2.1: Add FlattenConsecutive Layer"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class FlattenConsecutive(nn.Module):\n    def __init__(self, num_concat_ele):\n        super().__init__()  # Call to super()\n        self.num_concat_ele = num_concat_ele\n    def forward(self, X):\n        """\n        for example, if X is [4, 8, 10]  => [4, 4, 20] if num_concat_ele=2\n        """\n        X = X.view(X.shape[0], X.shape[1]//self.num_concat_ele, X.shape[2] * self.num_concat_ele)\n        X = X.squeeze() # if [4, 1, 10] then change to [4, 10]\n        return X\n\ndef build_network():\n    model = nn.Sequential(\n        nn.Embedding(num_embeddings=vocab_size, embedding_dim=embd_dim),\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=2 * embd_dim, out_features=n_hidden, bias=False),\n        nn.BatchNorm1d(num_features=n_hidden, momentum=0.001),\n        nn.Tanh(),\n\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=n_hidden * 2, out_features=n_hidden, bias=False),\n        nn.BatchNorm1d(num_features=n_hidden, momentum=0.001),\n\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=n_hidden * 2, out_features=vocab_size, bias=False),\n        nn.BatchNorm1d(num_features=vocab_size, momentum=0.001),\n    )\n    model[-1].weight.data *= 0.1 # make the last layer less confident\n    for p in model.parameters():\n        p.requires_grad = True\n    return model\n'})}),"\n",(0,o.jsx)(n.h3,{id:"step-222-adjust-the-batchnorm-dimension",children:"Step 2.2.2: Adjust the BatchNorm Dimension"}),"\n",(0,o.jsx)(n.p,{children:"From batchNorm Documentation"}),"\n",(0,o.jsx)(n.p,{children:"Shape:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Input: (N, C) or (N, C, L), where N is the batch size, C is the number of features or channels, and L is the sequence length"}),"\n",(0,o.jsx)(n.li,{children:"Output: (N, C) or (N, C, L) (same shape as input)"}),"\n"]}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsx)(n.p,{children:"The mean and standard-deviation are calculated per-dimension over the mini-batches and \u03b3 and \u03b2 are learnable parameter vectors of size C (where C is the number of features or channels of the input). By default, the elements of \u03b3 are set to 1 and the elements of \u03b2 are set to 0."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["However, when we put our input to the batchnorm dimention e.g., ",(0,o.jsx)(n.code,{children:"4 * 2 * 200"})]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"what we want for the bn_mean (indicated by gamma above) and bn_variance (indicated by beta above) are both of size [1 * 200]"}),"\n",(0,o.jsx)(n.li,{children:"i.e., we want the 200 to be C."}),"\n",(0,o.jsx)(n.li,{children:"so, we need a way for the second dimension to be 200."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Now we update the networks structure to include this additional dimension adjustment."}),"\n",(0,o.jsx)(n.p,{children:"Below we check how do we make second dimension 200 to be C:"}),"\n",(0,o.jsx)(n.p,{children:"Our goal is for the calculation of batchnorm to be the same."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"if X is of shape 2 * 2 * 3\n\n[[[1,2,3],\n\t[4,5,6]]\n  [[7,8,9],\n \t[10,11,12]]]\n \t\nwhat we want as bn_mean is [(1+4+7+10)/4, (2+5+8+11)/4, (3+6+9+12)/4] = [5.5, 6.5, 7.5]\n"})}),"\n",(0,o.jsx)(n.p,{children:"To achieve that, the most easy update is to make 4 * 2 * 200 to be 8 * 200."}),"\n",(0,o.jsx)(n.p,{children:"but what if we use X.view(X.shape[0], X.shape[2], X.shape[1]):"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"[[[1,2,3],\n\t[4,5,6]],\n\t\n  [[7,8,9],\n \t[10,11,12]]]\n \t\n \t\nbecomes\n\n[[[1,2],\n\t[3,4],\n\t[5,6]],\n\t\n  [7,8],\n\t[9,10],\n\t[11,12]]]\n\t\n\t\nwhen calculating mean over these dimensions we first get\n[[(1+2)/2,\n\t(3+4)/2,\n\t(5+6)/2],\n\t\n  [(7+8)/2,\n\t(9,10)/2,\n\t(11+12)/2]]\n\t\nthen we reduce these data\n\nwe can see that the mean is not the same as the above. \n"})}),"\n",(0,o.jsx)(n.p,{children:"So, we CANNOT use X.view(X.shape[0], X.shape[2], X.shape[1])."}),"\n",(0,o.jsx)(n.p,{children:"So, we have to flatten and un_flatten the dimensions before and after batchNorm."}),"\n",(0,o.jsx)(n.p,{children:"Below are how to use Flatten and Unflatten:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import torch\nfrom torch import nn\n\nx = torch.randn(4,2,200)\n\n"""\nFlatten from the 0th dimension onward, stop at 1th dimension\ni.e., the first part is [0, 1], both side included,\nthe second part is starting from dimension 2 to the end.\n\nif I do nn.Flatten(1,2), it will flatten 2 * 200, that way it is put to the second part of the result.\nResult will be 4 * 400\n"""\nflatten = nn.Flatten(0, 1)\noutput = flatten(x)\nprint(output.shape)\n\n"""\nunflatten syntax:\nnn.Unflatten(dim, unflattened_size)\ndim: The dimension that you want to "unflatten."\nunflattened_size: The target shape (as a tuple) of the dimension you\'re unflattening.\n"""\nunflatten = nn.Unflatten(0, (4,2))\noutput = unflatten(output)\nprint(output.shape)\n\nprint((output == x).all())\n'})}),"\n",(0,o.jsx)(n.p,{children:"output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"torch.Size([8, 200])\ntorch.Size([4, 2, 200])\ntensor(True)\n"})}),"\n",(0,o.jsx)(n.p,{children:"So, below is how we should build the model"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'\nclass FlattenConsecutive(nn.Module):\n    def __init__(self, num_concat_ele):\n        super().__init__()  # Call to super()\n        self.num_concat_ele = num_concat_ele\n\n    def forward(self, X):\n        """\n        for example, if X is [4, 8, 10]  => [4, 4, 20] if num_concat_ele=2\n        """\n        X = X.view(X.shape[0], X.shape[1] // self.num_concat_ele, X.shape[2] * self.num_concat_ele)\n        X = X.squeeze()  # if [4, 1, 10] then change to [4, 10]\n        return X\n\nclass Unflatten(nn.Module):\n    def __init__(self, num_folded_ele, num_features):\n        super().__init__()\n        self.num_folded_ele = num_folded_ele\n        self.num_features = num_features\n\n    def forward(self, X):\n        # [16, 200] needs to be revert back to [4, 4, 200]\n        X = X.view(-1, self.num_folded_ele, self.num_features)\n        return X\n\ndef build_network():\n    model = nn.Sequential(\n        nn.Embedding(num_embeddings=vocab_size, embedding_dim=embd_dim),\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=2 * embd_dim, out_features=n_hidden, bias=False),\n        nn.Flatten(0, 1), nn.BatchNorm1d(num_features=n_hidden, momentum=0.001), Unflatten(num_folded_ele=block_size//2, num_features=n_hidden),\n        nn.Tanh(),\n\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=n_hidden * 2, out_features=n_hidden, bias=False),\n        nn.Flatten(0, 1), nn.BatchNorm1d(num_features=n_hidden, momentum=0.001), Unflatten(num_folded_ele=block_size//4, num_features=n_hidden),\n\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=n_hidden * 2, out_features=vocab_size, bias=False),\n        nn.BatchNorm1d(num_features=vocab_size, momentum=0.001),\n    )\n    for layer in model:\n        layer.register_forward_hook(print_layer_shape)\n    model[-1].weight.data *= 0.1  # make the last layer less confident\n    for p in model.parameters():\n        p.requires_grad = True\n    return model\n\nbuild_network()\n'})}),"\n",(0,o.jsx)(n.h2,{id:"23-add-forward-hook-to-print-layer-shape",children:"2.3 Add Forward Hook to Print Layer Shape"}),"\n",(0,o.jsx)(n.p,{children:"We now add a forward hook to print layer shape, this is very useful for debug"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def print_layer_shape(layer, input, output):\n    print(f"{layer.__class__.__name__:20}: in: {str(input[0].shape):30}; out: {str(output.shape):30}")\n'})}),"\n",(0,o.jsx)(n.p,{children:"In the training function, add the line:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"    for layer in model:\n        layer.register_forward_hook(print_layer_shape)\n"})}),"\n",(0,o.jsx)(n.p,{children:"If we add a break after the first training iteration, it will give"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"Embedding           : in: torch.Size([100, 8])          ; out: torch.Size([100, 8, 10])      \nFlattenConsecutive  : in: torch.Size([100, 8, 10])      ; out: torch.Size([100, 4, 20])      \nLinear              : in: torch.Size([100, 4, 20])      ; out: torch.Size([100, 4, 200])     \nFlatten             : in: torch.Size([100, 4, 200])     ; out: torch.Size([400, 200])        \nBatchNorm1d         : in: torch.Size([400, 200])        ; out: torch.Size([400, 200])        \nUnflatten           : in: torch.Size([400, 200])        ; out: torch.Size([100, 4, 200])     \nTanh                : in: torch.Size([100, 4, 200])     ; out: torch.Size([100, 4, 200])     \nFlattenConsecutive  : in: torch.Size([100, 4, 200])     ; out: torch.Size([100, 2, 400])     \nLinear              : in: torch.Size([100, 2, 400])     ; out: torch.Size([100, 2, 200])     \nFlatten             : in: torch.Size([100, 2, 200])     ; out: torch.Size([200, 200])        \nBatchNorm1d         : in: torch.Size([200, 200])        ; out: torch.Size([200, 200])        \nUnflatten           : in: torch.Size([200, 200])        ; out: torch.Size([100, 2, 200])     \nFlattenConsecutive  : in: torch.Size([100, 2, 200])     ; out: torch.Size([100, 400])        \nLinear              : in: torch.Size([100, 400])        ; out: torch.Size([100, 27])         \nBatchNorm1d         : in: torch.Size([100, 27])         ; out: torch.Size([100, 27]) \n"})}),"\n",(0,o.jsx)(n.h1,{id:"3-final-code-and-output",children:"3. Final Code and Output"}),"\n",(0,o.jsx)(n.p,{children:"Below is the final code and final output, note that we removed the print message as that\u2019s for debugging purpose"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport random\nfrom torch import nn\n\nwords = open(\'makemore-master/names.txt\', \'r\').read().splitlines()\nwords = words\n\n# build the vocabulary of characters and mappings to/from integers\nchars = sorted(list(set(\'\'.join(words))))\nstoi = {s: i + 1 for i, s in enumerate(chars)}\nstoi[\'.\'] = 0\nitos = {i: s for s, i in stoi.items()}\nvocab_size = len(itos)\nprint(itos)\nprint(vocab_size)\n\n# build the dataset\nblock_size = 8  # context length: how many characters do we take to predict the next one?\n\ndef build_dataset(words):\n    X, Y = [], []\n\n    for w in words:\n        w = \'.\' * (block_size - 1) + w + "."\n        zip_data = []\n        for i in range(block_size):\n            zip_data.append(w[i:])\n        zip_data.append(w[block_size])\n        for data in zip(*zip_data):\n            X.append([stoi[ele] for ele in data[:-1]])\n            Y.append(stoi[data[-1]])\n    X = torch.tensor(X)\n    Y = torch.tensor(Y)\n    print(X.shape, Y.shape)\n    return X, Y\n\nrandom.seed(42)\nrandom.shuffle(words)\nn1 = int(0.8 * len(words))\nn2 = int(0.9 * len(words))\n\nXtr, Ytr = build_dataset(words[:n1])  # 80%\nXdev, Ydev = build_dataset(words[n1:n2])  # 10%\nXte, Yte = build_dataset(words[n2:])  # 10%s\n\n# MLP revisited\nembd_dim = 10  # the dimensionality of the character embedding vectors\nn_hidden = 200  # the number of neurons in the hidden layer of the MLP\n\nclass FlattenConsecutive(nn.Module):\n    def __init__(self, num_concat_ele):\n        super().__init__()  # Call to super()\n        self.num_concat_ele = num_concat_ele\n\n    def forward(self, X):\n        """\n        for example, if X is [4, 8, 10]  => [4, 4, 20] if num_concat_ele=2\n        """\n        X = X.view(X.shape[0], X.shape[1] // self.num_concat_ele, X.shape[2] * self.num_concat_ele)\n        X = X.squeeze()  # if [4, 1, 10] then change to [4, 10]\n        return X\n\nclass Unflatten(nn.Module):\n    def __init__(self, num_folded_ele, num_features):\n        super().__init__()\n        self.num_folded_ele = num_folded_ele\n        self.num_features = num_features\n\n    def forward(self, X):\n        # [16, 200] needs to be revert back to [4, 4, 200]\n        X = X.view(-1, self.num_folded_ele, self.num_features)\n        return X\n\ndef print_layer_shape(layer, input, output):\n    print(f"{layer.__class__.__name__:20}: in: {str(input[0].shape):30}; out: {str(output.shape):30}")\n\ndef build_network():\n    model = nn.Sequential(\n        nn.Embedding(num_embeddings=vocab_size, embedding_dim=embd_dim),\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=2 * embd_dim, out_features=n_hidden, bias=False),\n        nn.Flatten(0, 1), nn.BatchNorm1d(num_features=n_hidden, momentum=0.001),\n        Unflatten(num_folded_ele=block_size // 2, num_features=n_hidden),\n        nn.Tanh(),\n\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=n_hidden * 2, out_features=n_hidden, bias=False),\n        nn.Flatten(0, 1), nn.BatchNorm1d(num_features=n_hidden, momentum=0.001),\n        Unflatten(num_folded_ele=block_size // 4, num_features=n_hidden),\n\n        FlattenConsecutive(num_concat_ele=2),\n        nn.Linear(in_features=n_hidden * 2, out_features=vocab_size, bias=False),\n        nn.BatchNorm1d(num_features=vocab_size, momentum=0.001),\n    )\n    # for layer in model:\n    #     layer.register_forward_hook(print_layer_shape)\n    model[-1].weight.data *= 0.1  # make the last layer less confident\n    for p in model.parameters():\n        p.requires_grad = True\n    return model\n\nbuild_network()\n\nloss_fn = nn.CrossEntropyLoss()\nNUM_EPOCHS = 2\nstep_size = 0.1\n\ndef train(X, Y):\n    model = build_network()\n    lossi = []\n    dataset = torch.utils.data.TensorDataset(X, Y)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=100,\n                                             drop_last=True)  # use drop_last = true to avoid one sample batch\n    for i in range(NUM_EPOCHS):\n        for j, (train_x, train_y) in enumerate(dataloader):\n            for p in model.parameters():\n                p.grad = None\n            y_pred = model.forward(train_x)\n            loss = loss_fn(y_pred, train_y)\n            if j == len(dataloader) - 1 or j % 1000 == 0:\n                print(\n                    f"Epoch {i:3d}/{NUM_EPOCHS - 1:3d}, Batch {j:4d}/{len(dataloader) - 1:4d}, loss={loss.item():.4f}")\n            loss.backward()\n            lossi.append(loss.log10().item())\n            for p in model.parameters():\n                p.data -= step_size * p.grad\n    plt.plot(lossi)\n    plt.show()\n    return model\n\ng = torch.Generator().manual_seed(42)\n\ndef generate():\n    model = train(Xtr, Ytr)\n    word_lst = []\n    model.eval()\n    with torch.no_grad():\n        for _ in range(100):\n            xi = torch.zeros(1, 3, dtype=torch.int32)\n            cur_word = []\n            y = \'[INIT]\'\n            while y != ".":\n                y_prob = xi\n                y_prob = model.forward(y_prob)\n                y_prob = y_prob.softmax(dim=-1)\n                iy = torch.multinomial(y_prob, num_samples=1, generator=g).item()\n                y = itos[iy]\n                xi = torch.tensor([xi[0, 1:].tolist() + [iy]], dtype=torch.int32)\n                cur_word.append(y)\n            word_lst.append("".join(cur_word))\n\n    print(word_lst)\n\n# generate()\ndef calc_loss(model, X, Y):\n    y_logits = model.forward(X)\n    y_prob = y_logits.softmax(dim=-1)\n    loss = loss_fn(y_prob, Y)\n    return loss.item()\n\nmodel = train(Xtr, Ytr)\nprint("Train Loss: ", calc_loss(model, Xtr, Ytr))\nprint("Validation Loss: ", calc_loss(model, Xdev, Ydev))\n\n'})}),"\n",(0,o.jsx)(n.p,{children:"Output:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n27\ntorch.Size([25626, 8]) torch.Size([25626])\ntorch.Size([3203, 8]) torch.Size([3203])\ntorch.Size([3204, 8]) torch.Size([3204])\nEpoch   0/  1, Batch    0/ 255, loss=3.3114\nEpoch   0/  1, Batch  255/ 255, loss=2.0715\nEpoch   1/  1, Batch    0/ 255, loss=2.2137\nEpoch   1/  1, Batch  255/ 255, loss=1.9704\nTrain Loss:  3.1263720989227295\nValidation Loss:  3.1217050552368164\n"})}),"\n",(0,o.jsx)(n.p,{children:"Notice that we reduced train and validation loss even without any hyperparameter tuning."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>s});var a=t(96540);const o={},r=a.createContext(o);function i(e){const n=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);