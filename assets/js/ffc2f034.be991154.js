"use strict";(globalThis.webpackChunknotes=globalThis.webpackChunknotes||[]).push([[81467],{28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>m});var s=n(96540);const i={},r=s.createContext(i);function a(e){const t=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function m(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:t},e.children)}},55973:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>m,default:()=>l,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ML General/Support Vector Machine (SVM)","title":"Support Vector Machine (SVM)","description":"svm youtube","source":"@site/docs/05. ML General/29.Support Vector Machine (SVM).md","sourceDirName":"05. ML General","slug":"/p/e4b13962-3bfd-4179-9f05-8389360f76b6","permalink":"/notes/docs/p/e4b13962-3bfd-4179-9f05-8389360f76b6","draft":false,"unlisted":false,"editUrl":"https://github.com/emmableu/notes/edit/main/docs/05. ML General/29.Support Vector Machine (SVM).md","tags":[],"version":"current","sidebarPosition":29,"frontMatter":{"created_at":"2025-11-02","page_link":"/p/e4b13962-3bfd-4179-9f05-8389360f76b6","slug":"/p/e4b13962-3bfd-4179-9f05-8389360f76b6"},"sidebar":"tutorialSidebar","previous":{"title":"Linear Discrimitive Analysis (LDA)","permalink":"/notes/docs/p/d7874b72-4d46-49c8-9996-4b65598d8ed8"},"next":{"title":"Hierarchical Clustering","permalink":"/notes/docs/p/bc2360e2-3cde-44dd-ad53-b5cddfd713e7"}}');var i=n(74848),r=n(28453);const a={created_at:"2025-11-02",page_link:"/p/e4b13962-3bfd-4179-9f05-8389360f76b6",slug:"/p/e4b13962-3bfd-4179-9f05-8389360f76b6"},m=void 0,o={},c=[{value:"Intuitions, What is Support Vector",id:"intuitions-what-is-support-vector",level:2},{value:"Definition of Hyperplanes and Margin",id:"definition-of-hyperplanes-and-margin",level:2},{value:"Using Lagrangian Multipler Method to Maximize the Margin",id:"using-lagrangian-multipler-method-to-maximize-the-margin",level:2},{value:"Inner Products, similarity, and SVMs",id:"inner-products-similarity-and-svms",level:2},{value:"Non-Linear SVMs",id:"non-linear-svms",level:2},{value:"Soft margin, regularization, and Surrogate loss function",id:"soft-margin-regularization-and-surrogate-loss-function",level:2},{value:"Difference between SVM and Logistic Regression",id:"difference-between-svm-and-logistic-regression",level:2},{value:"How to choose which kernel to use",id:"how-to-choose-which-kernel-to-use",level:2}];function h(e){const t={a:"a",h2:"h2",img:"img",li:"li",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=efR1C6CvhmE&t=416s",children:"svm youtube"})}),"\n",(0,i.jsx)(t.p,{children:"margin: distance between observation and margin"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"maximum margin classifier problem: (problem with hard margins)"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"sensitive to outliers"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"soft margin: when we allow misclassifications, the distance between the observations and threshold is soft margin."}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"how to decide soft margin: use it as a hyperparameter and use cross validation"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"soft margin classifier / support vector classifier:"}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"what's support vector: the observations on the edge and within the soft margin are called support vectors."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/202209191710708.png",alt:""})}),"\n",(0,i.jsx)(t.p,{children:"the kernel trick:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"calculate the relationship between data as if they are in higher dimension (when they are actually not in higher dimension)."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"intuitions-what-is-support-vector",children:"Intuitions, What is Support Vector"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-0.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-1.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-2.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-3.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-4.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-5.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-6.png",width:"100%"}),"\n",(0,i.jsx)(t.h2,{id:"definition-of-hyperplanes-and-margin",children:"Definition of Hyperplanes and Margin"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-7.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-8.png",width:"100%"}),"\n",(0,i.jsx)(t.h2,{id:"using-lagrangian-multipler-method-to-maximize-the-margin",children:"Using Lagrangian Multipler Method to Maximize the Margin"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-9.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-10.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-11.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-12.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-13.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-14.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-15.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-16.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-17.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-18.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-19.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-20.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-21.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-22.png",width:"100%"}),"\n",(0,i.jsx)(t.h2,{id:"inner-products-similarity-and-svms",children:"Inner Products, similarity, and SVMs"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-23.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-24.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-25.png",width:"100%"}),"\n",(0,i.jsx)(t.h2,{id:"non-linear-svms",children:"Non-Linear SVMs"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-26.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-27.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-28.png",width:"100%"}),"\n",(0,i.jsx)(t.p,{children:"\u4e3e\u4e2a\u4f8b\u5b50\uff0c\u5bf9\u4e8e\u8fd9\u4e2a polynomial kernel (a*b + 1/2)^2, \u5176\u5b9e\u4e5f\u5c31\u662f = (a, a^2, 1/2) \u70b9\u4e58 (b, b^2, 1/2)"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-29.png",width:"100%"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-30.png",width:"100%"}),"\n",(0,i.jsx)(t.p,{children:"\u9664\u4e86\u4e0a\u9762\u8fd9\u4e09\u4e2a\uff0c\u8fd8\u6709\u4e00\u4e2a\u6bd4\u8f83\u5e38\u89c1\u7684\u662fGaussian kernel"}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-31.png",width:"100%"}),"\n",(0,i.jsx)(t.h2,{id:"soft-margin-regularization-and-surrogate-loss-function",children:"Soft margin, regularization, and Surrogate loss function"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-32.png",alt:""}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-33.png",alt:""}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-34.png",alt:""}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-35.png",alt:""}),"\n",(0,i.jsx)(t.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/svm-36.png",alt:""})]}),"\n",(0,i.jsx)(t.h2,{id:"difference-between-svm-and-logistic-regression",children:"Difference between SVM and Logistic Regression"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"LR gives calibrated probabilities that can be interpreted as confidence in a decision."}),"\n",(0,i.jsx)(t.li,{children:"LR gives us an unconstrained, smooth objective."}),"\n",(0,i.jsx)(t.li,{children:"SVMs don\u2019t penalize examples for which the correct decision is made with sufficient confidence. This may be good for generalization."}),"\n",(0,i.jsx)(t.li,{children:"SVMs have a nice dual form, giving sparse solutions when using the kernel trick (better scalability)"}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"how-to-choose-which-kernel-to-use",children:"How to choose which kernel to use"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"\uff081\uff09\u5982\u679c\u7279\u5f81\u7ef4\u6570\u5f88\u9ad8\uff0c\u5f80\u5f80\u7ebf\u6027\u53ef\u5206\uff0c\u53ef\u4ee5\u91c7\u7528LR\u6216\u8005\u7ebf\u6027\u6838\u7684SVM\uff1b"}),"\n",(0,i.jsx)(t.li,{children:"\uff082\uff09\u5982\u679c\u6837\u672c\u6570\u91cf\u5f88\u591a\uff0c\u7531\u4e8e\u6c42\u89e3\u6700\u4f18\u5316\u95ee\u9898\u7684\u65f6\u5019\uff0c\u76ee\u6807\u51fd\u6570\u6d89\u53ca\u4e24\u4e24\u6837\u672c\u8ba1\u7b97\u5185\u79ef\uff0c\u4f7f\u7528\u9ad8\u65af\u6838\u660e\u663e\u8ba1\u7b97\u91cf\u4f1a\u5927\u4e8e\u7ebf\u6027\u6838\uff0c\u6240\u4ee5\u624b\u52a8\u6dfb\u52a0\u4e00\u4e9b\u7279\u5f81\uff0c\u4f7f\u5f97\u7ebf\u6027\u53ef\u5206\uff0c\u7136\u540e\u53ef\u4ee5\u7528LR\u6216\u8005\u7ebf\u6027\u6838\u7684SVM\uff1b"}),"\n",(0,i.jsx)(t.li,{children:"\uff083\uff09\u5982\u679c\u4e0d\u6ee1\u8db3\u4e0a\u8ff0\u4e24\u70b9\uff0c\u5373\u7279\u5f81\u7ef4\u6570\u5c11\uff0c\u6837\u672c\u6570\u91cf\u6b63\u5e38\uff0c\u53ef\u4ee5\u4f7f\u7528\u9ad8\u65af\u6838/RBF\u6838\u7684SVM\u3002"}),"\n"]})]})}function l(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);