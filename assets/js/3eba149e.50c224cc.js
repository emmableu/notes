"use strict";(globalThis.webpackChunknotes=globalThis.webpackChunknotes||[]).push([[25805],{28453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>o});var t=r(96540);const s={},i=t.createContext(s);function l(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(i.Provider,{value:n},e.children)}},59285:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"DL Theory 100/RLHF pipeline for aligning LLMs steps SFT reward model PPO vs DPO vs RLAIF","title":"RLHF pipeline for aligning LLMs steps SFT reward model PPO vs DPO vs RLAIF","description":"\u5b9a\uff1aRLHF \u901a\u8fc7\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50 LLM\uff1aSFT \u5b66\u4f1a\u9075\u5faa\u6307\u4ee4\uff0cRM \u5b66\u504f\u597d\u6253\u5206\uff0cPPO \u6216 DPO/RLAIF \u7528\u504f\u597d\u4f18\u5316\u7b56\u7565\u3002","source":"@site/docs/02. DL Theory 100/003. RLHF pipeline for aligning LLMs steps SFT reward model PPO vs DPO vs RLAIF.md","sourceDirName":"02. DL Theory 100","slug":"/p/1d96dc28-f10a-4f2b-893f-e4223e5be261","permalink":"/notes/docs/p/1d96dc28-f10a-4f2b-893f-e4223e5be261","draft":false,"unlisted":false,"editUrl":"https://github.com/emmableu/notes/edit/main/docs/02. DL Theory 100/003. RLHF pipeline for aligning LLMs steps SFT reward model PPO vs DPO vs RLAIF.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"created_at":"2025-11-01","page_link":"/p/1d96dc28-f10a-4f2b-893f-e4223e5be261","slug":"/p/1d96dc28-f10a-4f2b-893f-e4223e5be261"},"sidebar":"tutorialSidebar","previous":{"title":"Self-Attention step by step implementation","permalink":"/notes/docs/p/43a96f3c-a9c2-4990-9538-c7601da9d719"},"next":{"title":"Differences between GPT decoder-only and BERT encoder-only models","permalink":"/notes/docs/p/4761e9f9-e130-45cd-8462-0e41b395dddd"}}');var s=r(74848),i=r(28453);const l={created_at:"2025-11-01",page_link:"/p/1d96dc28-f10a-4f2b-893f-e4223e5be261",slug:"/p/1d96dc28-f10a-4f2b-893f-e4223e5be261"},o=void 0,a={},d=[{value:"1. pretraining v.s. SFT v.s. RL (not RLHF yet):",id:"1-pretraining-vs-sft-vs-rl-not-rlhf-yet",level:3},{value:"RLHF: unverifiable domains",id:"rlhf-unverifiable-domains",level:3},{value:"RLHF Downside: Adversarial Examples",id:"rlhf-downside-adversarial-examples",level:3}];function c(e){const n={a:"a",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"\u5b9a\uff1aRLHF \u901a\u8fc7\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50 LLM\uff1aSFT \u5b66\u4f1a\u9075\u5faa\u6307\u4ee4\uff0cRM \u5b66\u504f\u597d\u6253\u5206\uff0cPPO \u6216 DPO/RLAIF \u7528\u504f\u597d\u4f18\u5316\u7b56\u7565\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u56e0\uff1a\u7eaf SFT \u6613\u201c\u542c\u8bdd\u4f46\u4e0d\u7a33\u201d\uff0cRLHF \u5c06\u201c\u66f4\u597d/\u66f4\u5b89\u5168\u201d\u7684\u4eba\u7c7b\u504f\u597d\u663e\u5f0f\u7eb3\u5165\u76ee\u6807\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u6cd5\uff1a\n1.\tSFT\uff1a\u6307\u4ee4\u6570\u636e\u76d1\u7763\u5fae\u8c03\uff1b\n2.\t\u504f\u597d\u6570\u636e\uff1aA/B \u5bf9\u6bd4\uff0c\u8bad\u7ec3 Reward Model r(x,y)\uff1b\n3.\tPPO\uff1a\u6700\u5927\u5316 E[r] \u4e14\u7528 clip \u7ea6\u675f KL\uff1b\n4.\tDPO\uff1a\u4e0d\u663e\u5f0f RM\uff0c\u76f4\u63a5\u4f18\u5316\u201c\u4f18\u4e8e\u52a3\u201d\u7684\u5bf9\u6bd4\u76ee\u6807\uff1b\n5.\tRLAIF\uff1a\u7528 AI-feedback \u66ff\u4eba\u7c7b\uff0c\u964d\u4f4e\u6210\u672c\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u679c\uff1a\u66f4\u5b89\u5168\u3001\u8fde\u8d2f\u3001\u5c11\u5e7b\u89c9\u7684\u8f93\u51fa\uff1b\u5bf9\u9f50\u4f01\u4e1a\u89c4\u8303\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u4f18\uff1a\u53ef\u63a7\u6027\u5f3a\uff0c\u53ef\u4e0e\u62d2\u7b54/\u7ea2\u7ebf\u7b56\u7565\u7ed3\u5408\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u7ec6\u8282 & \u4f8b\u5b50\nPrompt\uff1a\u201cExplain dropout briefly.\u201d\n\u2022\tSFT \u5b66\u201c\u5982\u4f55\u7ec4\u7ec7\u7b54\u6848\u201d\uff1b\n\u2022\t\u504f\u597d\u6807\u6ce8\uff1a\u9009\u201c\u51c6\u786e+\u7ed3\u6784\u597d\u201d>\u201c\u5570\u55e6/\u4e0d\u51c6\u201d\uff1b\n\u2022\tPPO\uff1a\u5728\u7b56\u7565 \u03c0\u03b8 \u4e0b\u751f\u6210 y\uff0cRM \u6253\u5206 r(x,y)\uff0c\u7528 clip \u9632 policy \u5d29\uff1b\n\u2022\tDPO\uff1a\u76f4\u63a5\u5b66\u4e60\u201c\u4f18\u6837\u672c\u80dc\u8fc7\u52a3\u6837\u672c\u201d\u7684\u6982\u7387\u3002"}),"\n",(0,s.jsx)(n.p,{children:"3 \u4e2a Follow-up\nA. \u201cPPO vs DPO \u53d6\u820d\uff1f\u201d DPO \u7b80\u5316\u8bad\u7ec3\u3001\u6613\u6536\u655b\uff1bPPO \u53ef\u76f4\u63a5\u63a5 RM \u4e0e online \u91c7\u6837\uff0c\u7cbe\u7ec6\u53ef\u63a7\u3002\nB. \u201cRM \u8fc7\u62df\u5408/\u504f\u5dee\uff1f\u201d \u6b63\u5219+\u591a\u6837\u6807\u6ce8+\u6821\u51c6\u8bc4\u6d4b\uff1b\u6df7\u5165\u5bf9\u6297\u6837\u672c\u3002\nC. \u201c\u6210\u672c\u5982\u4f55\u964d\u4f4e\uff1f\u201d RLAIF\u3001\u504f\u597d\u84b8\u998f\u3001\u4e3b\u52a8\u5b66\u4e60\u6311\u8fb9\u754c\u6837\u672c\u3002"}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"steps: (steps: SFT, reward model, PPO vs DPO vs RLAIF)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"1-pretraining-vs-sft-vs-rl-not-rlhf-yet",children:"1. pretraining v.s. SFT v.s. RL (not RLHF yet):"}),"\n",(0,s.jsxs)(n.p,{children:["(",(0,s.jsx)(n.a,{href:"https://www.youtube.com/watch?v=7xTGNNLPyMI&t=10106s",children:"https://www.youtube.com/watch?v=7xTGNNLPyMI&t=10106s"})," 2:08 - 2:28)"]}),"\n",(0,s.jsx)(n.p,{children:"\u7c7b\u6bd4\uff1a\npretraining\u662f\u770b\u4e66\u5b66\u4e60\u77e5\u8bc6\nsft\u662f\u770bworked example\uff0c\u6709\u6807\u51c6\u7b54\u6848\nrlhf\u662f\u505a\u9898\uff0c\u7ed9\u95ee\u9898\uff0c\u7ed9\u6700\u7ec8\u7b54\u6848\uff0c\u627e\u5230\u597d\u7684\u63a8\u7406\u8fc7\u7a0b\u53ef\u4ee5\u5f97\u5230\u6b63\u786e\u7684\u6700\u7ec8\u7b54\u6848"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/202511022059254.png",alt:""})}),"\n",(0,s.jsx)(n.h3,{id:"rlhf-unverifiable-domains",children:"RLHF: unverifiable domains"}),"\n",(0,s.jsx)(n.p,{children:"\u6bd4\u5982\u8ba9llm\u521b\u4f5cjoke"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"\u5148\u6784\u5efareward model\uff0ctraining data\u662fhuman\u7ed95\u4e2ajoke\u6392\u5e8f\uff0coutput\u662frewardmodel\u7684reward score"}),"\n",(0,s.jsx)(n.li,{children:"\u518d\u7528rlhf\u7528rewardmodel\u7684\u7ed3\u679c\u4f5c\u4e3arl\u7684\u76ee\u6807\uff0ce.g.\uff0c\u4ea7\u751f15\u4e2a\u7ed3\u679c\uff0c\u53ea\u67094\u4e2a\u662f\u9ad8reward\uff0c\u7528\u9ad8reward\u7684\u7ed3\u679c\uff0ctrain on it\uff0crepeat many many times"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/202511022100933.png",alt:""})}),"\n",(0,s.jsx)(n.h3,{id:"rlhf-downside-adversarial-examples",children:"RLHF Downside: Adversarial Examples"}),"\n",(0,s.jsx)(n.p,{children:'e.g.\uff0c\u901a\u8fc7\u591a\u6b21reinforcement learning\uff0c\u8fd9\u4e2arlmodel\u53d1\u73b0\u4e86\u5982\u4f55game \u8fd9\u4e2areward model\uff0c\u6bd4\u5982\uff0c \u7528\u201cthe the the the the" \u4f5c\u4e3a\u4e00\u4e2atop joke\uff0c\u8fd9\u4e2a\u5176\u5b9e\u662f\u4e00\u4e2a\u4e0d\u4f1a\u88abmodel training train\u5230\u7684edge case\uff0c\u4f46\u662f\u4f1a\u8ba9reward model\u4ea7\u751f\u9ad8\u5206\u3002'}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"solution:"})," rlhf \u5fc5\u987b\u5f97\u53ca\u65f6crop\uff0c\u4e0d\u7136\u7684\u8bdd\u4f1a\u7ed3\u679c\u8d8a\u6765\u8d8a\u5dee"]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);