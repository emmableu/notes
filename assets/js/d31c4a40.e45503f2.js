"use strict";(globalThis.webpackChunknotes=globalThis.webpackChunknotes||[]).push([[7281],{28453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>l});var r=t(96540);const i={},s=r.createContext(i);function a(n){const e=r.useContext(s);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),r.createElement(s.Provider,{value:e},n.children)}},54600:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"Zero To Hero/Makemore 1.1 - bigram - Train and Evaluate a Bigram Model","title":"Makemore 1.1 - bigram - Train and Evaluate a Bigram Model","description":"Youtube link//www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2","source":"@site/docs/04. Zero To Hero/02.Makemore 1.1 - bigram - Train and Evaluate a Bigram Model.md","sourceDirName":"04. Zero To Hero","slug":"/p/d9d7f60b-8e6c-4fcd-a40d-6e44deaca3c8","permalink":"/notes/docs/p/d9d7f60b-8e6c-4fcd-a40d-6e44deaca3c8","draft":false,"unlisted":false,"editUrl":"https://github.com/emmableu/notes/edit/main/docs/04. Zero To Hero/02.Makemore 1.1 - bigram - Train and Evaluate a Bigram Model.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"created_at":"2025-11-02","page_link":"/p/d9d7f60b-8e6c-4fcd-a40d-6e44deaca3c8","slug":"/p/d9d7f60b-8e6c-4fcd-a40d-6e44deaca3c8"},"sidebar":"tutorialSidebar","previous":{"title":"Resources","permalink":"/notes/docs/p/e8a79d58-7f55-415e-a4b9-25657b36ea95"},"next":{"title":"Makemore 1.2 - trigram 1","permalink":"/notes/docs/p/34b50f11-765b-4bf1-9b91-7232cedd6a34"}}');var i=t(74848),s=t(28453);const a={created_at:"2025-11-02",page_link:"/p/d9d7f60b-8e6c-4fcd-a40d-6e44deaca3c8",slug:"/p/d9d7f60b-8e6c-4fcd-a40d-6e44deaca3c8"},l="\u7b2c\u4e00\u90e8\u5206\uff1a\u4f7f\u7528 Bigram \u6982\u7387\u751f\u6210\u65b0\u7684 Bigram \u6837\u672c",o={},d=[{value:"1.1 \ud83e\uddee \u7b2c\u4e00\u6b65\uff081.1\uff09\uff1a\u521b\u5efa Bigram \u8ba1\u6570\u77e9\u9635 N",id:"11--\u7b2c\u4e00\u6b6511\u521b\u5efa-bigram-\u8ba1\u6570\u77e9\u9635-n",level:2},{value:"Problem Definition",id:"problem-definition",level:3},{value:"Code implementation",id:"code-implementation",level:3},{value:"Step 1.2: \u7b2c2\u6b65\uff081.2\uff09\uff1a\u4f7f\u7528\u591a\u5143\u6982\u7387\u5206\u5e03\u751f\u6210\u65b0\u7684\u6837\u672c",id:"step-12-\u7b2c2\u6b6512\u4f7f\u7528\u591a\u5143\u6982\u7387\u5206\u5e03\u751f\u6210\u65b0\u7684\u6837\u672c",level:2},{value:"\u30101.3.1. \u521b\u5efa bigram \u6982\u7387\u77e9\u9635\u3011",id:"131-\u521b\u5efa-bigram-\u6982\u7387\u77e9\u9635",level:3},{value:"\u63cf\u8ff0\uff1a",id:"\u63cf\u8ff0",level:4},{value:"\u51fd\u6570\u7b7e\u540d\uff1a",id:"\u51fd\u6570\u7b7e\u540d",level:4},{value:"\u8f93\u5165\u793a\u4f8b\uff1a",id:"\u8f93\u5165\u793a\u4f8b",level:4},{value:"\u8f93\u51fa\u793a\u4f8b\uff1a",id:"\u8f93\u51fa\u793a\u4f8b",level:4},{value:"Implementation",id:"implementation",level:3},{value:"\u3010\u9898\u76ee 2. \u6dfb\u52a0\u6b63\u5219\u5316\u907f\u514d\u9664\u4ee5 0\u3011",id:"\u9898\u76ee-2-\u6dfb\u52a0\u6b63\u5219\u5316\u907f\u514d\u9664\u4ee5-0",level:3},{value:"\u63cf\u8ff0\uff1a",id:"\u63cf\u8ff0-1",level:4},{value:"\u51fd\u6570\u7b7e\u540d\uff1a",id:"\u51fd\u6570\u7b7e\u540d-1",level:4},{value:"\u8f93\u5165\u793a\u4f8b\uff1a",id:"\u8f93\u5165\u793a\u4f8b-1",level:4},{value:"\u8f93\u51fa\u793a\u4f8b\uff1a",id:"\u8f93\u51fa\u793a\u4f8b-1",level:4},{value:"Implementation",id:"implementation-1",level:4},{value:"\u3010\u9898\u76ee 3. \u9a8c\u8bc1 bigram \u6982\u7387\u77e9\u9635\u3011",id:"\u9898\u76ee-3-\u9a8c\u8bc1-bigram-\u6982\u7387\u77e9\u9635",level:3},{value:"\u63cf\u8ff0\uff1a",id:"\u63cf\u8ff0-2",level:4},{value:"\u51fd\u6570\u7b7e\u540d\uff1a",id:"\u51fd\u6570\u7b7e\u540d-2",level:4},{value:"\u8f93\u5165\u793a\u4f8b\uff1a",id:"\u8f93\u5165\u793a\u4f8b-2",level:4},{value:"\u8f93\u51fa\u793a\u4f8b\uff1a",id:"\u8f93\u51fa\u793a\u4f8b-2",level:4},{value:"Implementation\uff1a",id:"implementation-2",level:4},{value:"\u3010\u9898\u76ee 4. \u4f7f\u7528 bigram \u6982\u7387\u751f\u6210\u5355\u8bcd\u3011",id:"\u9898\u76ee-4-\u4f7f\u7528-bigram-\u6982\u7387\u751f\u6210\u5355\u8bcd",level:3},{value:"\u63cf\u8ff0\uff1a",id:"\u63cf\u8ff0-3",level:4},{value:"\u51fd\u6570\u7b7e\u540d\uff1a",id:"\u51fd\u6570\u7b7e\u540d-3",level:4},{value:"\u8f93\u5165\u793a\u4f8b\uff1a",id:"\u8f93\u5165\u793a\u4f8b-3",level:4},{value:"\u8f93\u51fa\u793a\u4f8b\uff1a",id:"\u8f93\u51fa\u793a\u4f8b-3",level:4},{value:"Implementation",id:"implementation-3",level:4},{value:"\u3010\u9898\u76ee 5. \u7efc\u5408exercise1 \u5f97\u5230\u7ed3\u679c\u3011",id:"\u9898\u76ee-5-\u7efc\u5408exercise1-\u5f97\u5230\u7ed3\u679c",level:3},{value:"\ud83e\udde9 \u9898\u76ee\u603b\u89c8",id:"-\u9898\u76ee\u603b\u89c8",level:2},{value:"\ud83e\uddea \u9898\u76ee 1\uff1a\u51c6\u5907\u8bad\u7ec3\u6570\u636e\uff08X \u548c y\uff09",id:"-\u9898\u76ee-1\u51c6\u5907\u8bad\u7ec3\u6570\u636ex-\u548c-y",level:2},{value:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a",id:"-\u9898\u76ee\u63cf\u8ff0",level:3},{value:"\ud83d\udce5 \u8f93\u5165\u793a\u4f8b\uff1a",id:"-\u8f93\u5165\u793a\u4f8b",level:3},{value:"\ud83d\udce4 \u8f93\u51fa\u793a\u4f8b\uff1a",id:"-\u8f93\u51fa\u793a\u4f8b",level:3},{value:"\ud83e\uddfe \u51fd\u6570\u7b7e\u540d\uff1a",id:"-\u51fd\u6570\u7b7e\u540d",level:3},{value:"\u2705 \u6d4b\u8bd5\u7528\u4f8b\uff1a",id:"-\u6d4b\u8bd5\u7528\u4f8b",level:3},{value:"Implementation\uff1a",id:"implementation-4",level:3},{value:"\ud83e\uddea \u9898\u76ee 2\uff1a\u6570\u636e\u96c6\u5212\u5206\uff08Train-Test Split\uff09",id:"-\u9898\u76ee-2\u6570\u636e\u96c6\u5212\u5206train-test-split",level:2},{value:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a",id:"-\u9898\u76ee\u63cf\u8ff0-1",level:3},{value:"\ud83d\udce5 \u8f93\u5165\uff1a",id:"-\u8f93\u5165",level:3},{value:"\ud83d\udce4 \u8f93\u51fa\uff1a",id:"-\u8f93\u51fa",level:3},{value:"\ud83e\uddfe \u51fd\u6570\u7b7e\u540d\uff1a",id:"-\u51fd\u6570\u7b7e\u540d-1",level:3},{value:"\u2705 \u6d4b\u8bd5\u7528\u4f8b\uff1a",id:"-\u6d4b\u8bd5\u7528\u4f8b-1",level:3},{value:"\u2705 Implementation",id:"-implementation",level:3},{value:"\ud83e\uddea \u9898\u76ee 3\uff1a\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u5e76\u8bad\u7ec3",id:"-\u9898\u76ee-3\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u5e76\u8bad\u7ec3",level:2},{value:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a",id:"-\u9898\u76ee\u63cf\u8ff0-2",level:3},{value:"\ud83d\udce5 \u8f93\u5165\uff1a",id:"-\u8f93\u5165-1",level:3},{value:"\ud83d\udce4 \u8f93\u51fa\uff1a",id:"-\u8f93\u51fa-1",level:3},{value:"\u2705 Implementation",id:"-implementation-1",level:3},{value:"\ud83e\uddea \u9898\u76ee 4\uff1a\u751f\u6210\u540d\u5b57",id:"-\u9898\u76ee-4\u751f\u6210\u540d\u5b57",level:2},{value:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a",id:"-\u9898\u76ee\u63cf\u8ff0-3",level:3},{value:"\ud83d\udce4 \u8f93\u51fa\u793a\u4f8b\uff1a",id:"-\u8f93\u51fa\u793a\u4f8b-1",level:3},{value:"\ud83e\uddfe \u51fd\u6570\u7b7e\u540d\uff1a",id:"-\u51fd\u6570\u7b7e\u540d-2",level:3},{value:"\u2705 Implementation",id:"-implementation-2",level:3},{value:"Example 1: Concatenating 2D Tensors",id:"example-1-concatenating-2d-tensors",level:3},{value:"<strong>Concatenate along\xa0<code>dim=0</code></strong>\xa0(rows): - means expanding on number of rows.",id:"concatenate-alongdim0rows---means-expanding-on-number-of-rows",level:3},{value:"<strong>Concatenate along\xa0<code>dim=1</code></strong>\xa0(columns):",id:"concatenate-alongdim1columns",level:3}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(e.p,{children:["Youtube link: ",(0,i.jsx)(e.a,{href:"https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2",children:"https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=2"})]}),"\n",(0,i.jsxs)(e.p,{children:["github link: ",(0,i.jsx)(e.a,{href:"https://github.com/karpathy/makemore",children:"https://github.com/karpathy/makemore"})]}),"\n",(0,i.jsxs)(e.p,{children:["jupyter notebook: ",(0,i.jsx)(e.a,{href:"https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbWtKMk5XaW81QzJMTjVFSUhvdG9kMlo4ZGgyQXxBQ3Jtc0ttMmNrUUNDcWJFcHYxWUdFV3J0ZkppVE1HUG1yZktyUE52QmMzTWxZWW90c280N3NVeG55ekFibF9vdlluTnBBRFhDc2FnZ29hdjdiaGVxeVhleUczcWdpQ0pqcnNQbHozUUNacWlTbE91OFllMmpUcw&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fnn-zero-to-hero%2Fblob%2Fmaster%2Flectures%2Fmakemore%2Fmakemore_part1_bigrams.ipynb&v=PaCmpygFfXo"}),(0,i.jsx)(e.a,{href:"https://github.com/karpathy/nn-zero-t",children:"https://github.com/karpathy/nn-zero-t"}),"..."]}),"\n",(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"\u7b2c\u4e00\u90e8\u5206\u4f7f\u7528-bigram-\u6982\u7387\u751f\u6210\u65b0\u7684-bigram-\u6837\u672c",children:"\u7b2c\u4e00\u90e8\u5206\uff1a\u4f7f\u7528 Bigram \u6982\u7387\u751f\u6210\u65b0\u7684 Bigram \u6837\u672c"})}),"\n",(0,i.jsx)(e.p,{children:"Use the probabilities to generate new sequence of names, that looks like"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:".aylandia.\n.hosannaleine.\n.pieliyya.\n.jeah.\n.drielana.\n.anishlia.\n.el.\n.comon.\n...\n"})}),"\n",(0,i.jsx)(e.h2,{id:"11--\u7b2c\u4e00\u6b6511\u521b\u5efa-bigram-\u8ba1\u6570\u77e9\u9635-n",children:"1.1 \ud83e\uddee \u7b2c\u4e00\u6b65\uff081.1\uff09\uff1a\u521b\u5efa Bigram \u8ba1\u6570\u77e9\u9635 N"}),"\n",(0,i.jsx)(e.h3,{id:"problem-definition",children:"Problem Definition"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"N[1,2]"}),' means how many counts of bigram are "abc".']}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.code,{children:"N[1,:].sum()"}),' means the number of all bigram that starts with "a".']}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:"e.g., if input is"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"abba\nbabao\n"})}),"\n",(0,i.jsx)(e.p,{children:"because this means"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:".a: 1\nab: 1\nbb: 1\nba: 1\na.: 1\n==\n.b: 1\nba: 1\nab: 1\nba: 1\nao: 1\no.: 1\n"})}),"\n",(0,i.jsx)(e.p,{children:"it sums up to"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:(0,i.jsx)(e.strong,{children:"Key"})}),(0,i.jsx)(e.th,{children:(0,i.jsx)(e.strong,{children:"Total Count"})})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:".a"}),(0,i.jsx)(e.td,{children:"1"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"ab"}),(0,i.jsx)(e.td,{children:"2 (1 + 1)"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"bb"}),(0,i.jsx)(e.td,{children:"1"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"ba"}),(0,i.jsx)(e.td,{children:"3 (1 + 1 + 1)"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"a."}),(0,i.jsx)(e.td,{children:"1"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:".b"}),(0,i.jsx)(e.td,{children:"1"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"ao"}),(0,i.jsx)(e.td,{children:"1"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"o."}),(0,i.jsx)(e.td,{children:"1"})]})]})]}),"\n",(0,i.jsx)(e.p,{children:"i.e., this matrix should look like"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# 27x27 Bigram Frequency Matrix ('.' = 0, 'a'\u2013'z' = 1\u201326)\nbigram_matrix = [\n  #  .  a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q  r  s  t  u  v  w  x  y  z\n  [ 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # .\n  [ 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # a\n  [ 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # b\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # c\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # d\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # e\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # f\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # g\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # h\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # i\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # j\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # k\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # l\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # m\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # n\n  [ 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # o\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # p\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # q\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # r\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # s\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # t\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # u\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # v\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # w\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # x\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # y\n  [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # z\n]\n"})}),"\n",(0,i.jsx)(e.h3,{id:"code-implementation",children:"Code implementation"}),"\n",(0,i.jsxs)(e.p,{children:["here\u2019s the names.txt file: ",(0,i.jsx)(e.a,{href:"https://github.com/karpathy/makemore/blob/master/names.txt",children:"https://github.com/karpathy/makemore/blob/master/names.txt"})]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import torch  \nfilename = \"../../makemore/names.txt\"  \ndef name_to_bigram(filename):  \n    names = open(filename).read().splitlines()  \n    N = torch.zeros(27, 27)  \n    itos = '.abcdefghijklmnopqrstuvwxyz'  \n    stoi = {ele:i for i, ele in enumerate(itos)}  \n    for name in names:  \n        ele = ['.'] + [c for c in name] + ['.']  \n        for ch1, ch2 in zip(ele, ele[1:]):  \n            N[stoi[ch1], stoi[ch2]] += 1  \n    return N  \n  \nN = name_to_bigram(filename)  \nprint(N.to(dtype=torch.int32))\n"})}),"\n",(0,i.jsx)(e.h2,{id:"step-12-\u7b2c2\u6b6512\u4f7f\u7528\u591a\u5143\u6982\u7387\u5206\u5e03\u751f\u6210\u65b0\u7684\u6837\u672c",children:"Step 1.2: \u7b2c2\u6b65\uff081.2\uff09\uff1a\u4f7f\u7528\u591a\u5143\u6982\u7387\u5206\u5e03\u751f\u6210\u65b0\u7684\u6837\u672c"}),"\n",(0,i.jsx)(e.h3,{id:"131-\u521b\u5efa-bigram-\u6982\u7387\u77e9\u9635",children:"\u30101.3.1. \u521b\u5efa bigram \u6982\u7387\u77e9\u9635\u3011"}),"\n",(0,i.jsx)(e.h4,{id:"\u63cf\u8ff0",children:"\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsxs)(e.p,{children:["\u7ed9\u5b9a\u4e00\u4e2a bigram \u9891\u7387\u7edf\u8ba1\u77e9\u9635 ",(0,i.jsx)(e.code,{children:"N"}),"\uff0c\u8bf7\u521b\u5efa\u4e00\u4e2a\u6982\u7387\u77e9\u9635 ",(0,i.jsx)(e.code,{children:"prob_matrix"}),"\uff0c\u5176\u4e2d ",(0,i.jsx)(e.code,{children:"prob_matrix[i][j]"})," \u8868\u793a\u5728\u5b57\u6bcd ",(0,i.jsx)(e.code,{children:"i"})," \u51fa\u73b0\u540e\uff0c\u5b57\u6bcd ",(0,i.jsx)(e.code,{children:"j"})," \u51fa\u73b0\u7684\u6982\u7387\u3002"]}),"\n",(0,i.jsx)(e.h4,{id:"\u51fd\u6570\u7b7e\u540d",children:"\u51fd\u6570\u7b7e\u540d\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def build_bigram_probability_matrix(N: torch.tensor) -> torch.tensor:\n    pass\n"})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u5165\u793a\u4f8b",children:"\u8f93\u5165\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"N = [\n  [1, 3, 1],\n  [2, 0, 4],\n]\n"})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u51fa\u793a\u4f8b",children:"\u8f93\u51fa\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"[\n  [0.2, 0.6, 0.2],\n  [0.333, 0.0, 0.666],\n]\n"})}),"\n",(0,i.jsx)(e.h3,{id:"implementation",children:"Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import torch\ndef build_bigram_probability_matrix(N: torch.tensor) -> torch.tensor:\n    prob_matrix = N\n    sum = N.sum(dim=1, keepdim=True) # [2,3] => [2, 1] * must have keepdim *\n    prob_matrix = prob_matrix/sum\n    return prob_matrix\n\nN = torch.tensor([\n    [1, 3, 1],\n    [2, 0, 4]\n], dtype=torch.float)\n\nexpected = torch.tensor([\n    [0.2, 0.6, 0.2],\n    [2/6, 0.0, 4/6]\n], dtype=torch.float)\n\nresult = build_bigram_probability_matrix(N)\nassert torch.allclose(result, expected, atol=1e-3), "Test case 1 failed"\n'})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h3,{id:"\u9898\u76ee-2-\u6dfb\u52a0\u6b63\u5219\u5316\u907f\u514d\u9664\u4ee5-0",children:"\u3010\u9898\u76ee 2. \u6dfb\u52a0\u6b63\u5219\u5316\u907f\u514d\u9664\u4ee5 0\u3011"}),"\n",(0,i.jsx)(e.h4,{id:"\u63cf\u8ff0-1",children:"\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsx)(e.p,{children:"\u5728\u5b9e\u9645\u60c5\u51b5\u4e2d\uff0c\u67d0\u4e9b\u884c\u7684\u548c\u53ef\u80fd\u4e3a 0\uff08\u8868\u793a\u8be5 bigram \u4ece\u672a\u51fa\u73b0\uff09\uff0c\u4e3a\u907f\u514d NaN \u51fa\u73b0\uff0c\u8bf7\u4e3a\u6bcf\u4e2a\u5143\u7d20\u6dfb\u52a0\u4e00\u4e2a\u4f2a\u8ba1\u6570\uff08\u5982 +1\uff09\u540e\u518d\u8ba1\u7b97\u6982\u7387\u3002"}),"\n",(0,i.jsx)(e.h4,{id:"\u51fd\u6570\u7b7e\u540d-1",children:"\u51fd\u6570\u7b7e\u540d\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def build_bigram_probability_with_smoothing(N: torch.tensor) -> torch.tensor:\n\tpass\n"})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u5165\u793a\u4f8b-1",children:"\u8f93\u5165\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"N = [\n  [0, 0, 0],\n  [2, 0, 4],\n]\n"})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u51fa\u793a\u4f8b-1",children:"\u8f93\u51fa\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"[\n  [0.333, 0.333, 0.333],\n  [0.375, 0.125, 0.5],\n]\n"})}),"\n",(0,i.jsx)(e.h4,{id:"implementation-1",children:"Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import torch  \n  \ndef build_bigram_probability_with_smoothing(N):  \n    smoothed = N + torch.ones(1)  \n    row_sums = smoothed.sum(dim=1, keepdim=True)  \n    prob_matrix = smoothed / row_sums  \n    return prob_matrix  \n  \n  \nN = torch.tensor([  \n    [0, 0, 0],  \n    [2, 0, 4],  \n])  \n  \nexpected = torch.tensor([  \n    [1/3, 1/3, 1/3],  \n    [3/9, 1/9, 5/9],  \n], dtype=torch.float)  \n  \nresult = build_bigram_probability_with_smoothing(N)  \nassert torch.allclose(result, expected, atol=1e-3)\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h3,{id:"\u9898\u76ee-3-\u9a8c\u8bc1-bigram-\u6982\u7387\u77e9\u9635",children:"\u3010\u9898\u76ee 3. \u9a8c\u8bc1 bigram \u6982\u7387\u77e9\u9635\u3011"}),"\n",(0,i.jsx)(e.h4,{id:"\u63cf\u8ff0-2",children:"\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsx)(e.p,{children:"\u9a8c\u8bc1\u6982\u7387\u77e9\u9635\u7684\u6bcf\u4e00\u884c\u4e4b\u548c\u662f\u5426\u4e3a 1\uff08\u8bef\u5dee\u5141\u8bb8\u8303\u56f4 < 1e-3\uff09"}),"\n",(0,i.jsx)(e.h4,{id:"\u51fd\u6570\u7b7e\u540d-2",children:"\u51fd\u6570\u7b7e\u540d\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def validate_probability_matrix(prob_matrix: torch.tensor) -> bool:\n\tpass\n"})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u5165\u793a\u4f8b-2",children:"\u8f93\u5165\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"prob_matrix = [\n  [0.2, 0.6, 0.2],\n  [0.333, 0.0, 0.666],\n  [0.0, 0.666, 0.333],\n]\n"})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u51fa\u793a\u4f8b-2",children:"\u8f93\u51fa\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"True\n"})}),"\n",(0,i.jsx)(e.h4,{id:"implementation-2",children:"Implementation\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import torch\ndef validate_probability_matrix(prob_matrix: torch.tensor) -> bool:\n\texpected = torch.ones(prob_matrix.shape[0])\n\treturn torch.allclose(prob_matrix.sum(dim=1), expected, atol=1e-3)\n\nprob_matrix = torch.tensor([\n    [0.2, 0.6, 0.2],\n    [0.333, 0.0, 0.667],  # \u8fd9\u91cc\u539f\u672c\u5199 0.666, \u6539\u4e3a 0.667 \u66f4\u7b26\u5408 float \u7cbe\u5ea6\n    [0.0, 0.666, 0.334],  # \u540c\u6837\u5904\u7406\u6700\u540e\u4e00\u884c\n], dtype=torch.float)\n\nassert validate_probability_matrix(prob_matrix) == True, "Validation failed"\nprint("Validation passed \u2705")\n'})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h3,{id:"\u9898\u76ee-4-\u4f7f\u7528-bigram-\u6982\u7387\u751f\u6210\u5355\u8bcd",children:"\u3010\u9898\u76ee 4. \u4f7f\u7528 bigram \u6982\u7387\u751f\u6210\u5355\u8bcd\u3011"}),"\n",(0,i.jsx)(e.h4,{id:"\u63cf\u8ff0-3",children:"\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsx)(e.p,{children:'\u6839\u636e\u7ed9\u5b9a\u7684 bigram \u6982\u7387\u77e9\u9635\uff0c\u751f\u6210\u591a\u4e2a\u4ee5 "." \u5f00\u5934\u5e76\u4ee5 "." \u7ed3\u5c3e\u7684\u968f\u673a\u5355\u8bcd\u3002'}),"\n",(0,i.jsx)(e.h4,{id:"\u51fd\u6570\u7b7e\u540d-3",children:"\u51fd\u6570\u7b7e\u540d\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def generate_words(prob_matrix: torch.tensor, itos: str, num_words: int) -> List[str]:\n    pass\n"})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u5165\u793a\u4f8b-3",children:"\u8f93\u5165\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'itos = ".ab"\nprob_matrix = [\n  [0.5, 0.3, 0.2],\n  [0.1, 0.7, 0.2],\n  [0.1, 0.7, 0.2],\n]\nnum_words = 4\n'})}),"\n",(0,i.jsx)(e.h4,{id:"\u8f93\u51fa\u793a\u4f8b-3",children:"\u8f93\u51fa\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'[".ab.", ".ba.", "ab", "b."]\n'})}),"\n",(0,i.jsx)(e.h4,{id:"implementation-3",children:"Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import torch\nfrom typing import List\ndef generate_words(prob_matrix: torch.tensor, itos: str, num_words: int) -> List[str]:\n    def dfs(i, cur_path, prob_matrix):\n        if i == 0 and len(cur_path) > 0:\n            return cur_path\n        dist = torch.distributions.Categorical(prob_matrix[i])\n        next_i = dist.sample((1,)).item()\n        return dfs(next_i, cur_path + [next_i], prob_matrix)\n\n    out = []\n    for _ in range(num_words):\n        path = dfs(0, [], prob_matrix)\n        word = \"\".join([itos[ele] for ele in path])\n        out.append(word)\n    return out\n\n\nitos = \".ab\"\nprob_matrix = torch.tensor([\n    [0.5, 0.3, 0.2], # starts with .\n    [0.1, 0.7, 0.2], # starts with a\n    [0.1, 0.1, 0.9], # starts with b\n], dtype=torch.float)\nwords = generate_words(prob_matrix, itos, num_words=10)\nprint(words)\n# output: ['abbbbbbb.', '.', 'aaaaaa.', 'abb.', 'aaaaaabbbbbbbbbbbbbba.', 'bbbbaaa.', '.', '.', 'abbbb.', 'aabbbbbbaaaababbbbbbbbbbbbbbabbabbbbbb.']\n\n\nfrom collections import Counter  \nitos = \".ab\"  \nprob_matrix = torch.tensor([  \n    [0.3, 0.3, 0.3], # starts with .  \n    [0.3, 0.3, 0.3], # starts with a  \n    [0.3, 0.3, 0.3], # starts with b  \n], dtype=torch.float)  \nwords = generate_words(prob_matrix, itos, num_words=10)  \nprint(words)  \nchars = []  \nfor w in words:  \n    for c in w:  \n        chars.append(c)  \nprint(Counter(chars))\n# output: ['aa.', '.', 'a.', '.', 'babbabbbb.', 'b.', '.', '.', '.', 'b.']\n# Counter({'.': 10, 'b': 9, 'a': 5})\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h3,{id:"\u9898\u76ee-5-\u7efc\u5408exercise1-\u5f97\u5230\u7ed3\u679c",children:"\u3010\u9898\u76ee 5. \u7efc\u5408exercise1 \u5f97\u5230\u7ed3\u679c\u3011"}),"\n",(0,i.jsx)(e.p,{children:"input\uff1a names.txt\noutput: a list of names, e.g.,"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:".aylandia.\n.hosannaleine.\n.pieliyya.\n.jeah.\n.drielana.\n.anishlia.\n.el.\n.comon.\n...\n"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import torch  \nfrom typing import List  \n  \nfilename = \"../../makemore/names.txt\"  \n  \n  \ndef name_to_bigram(filename):  \n    names = open(filename).read().splitlines()  \n    N = torch.zeros(27, 27)  \n    itos = '.abcdefghijklmnopqrstuvwxyz'  \n    stoi = {ele: i for i, ele in enumerate(itos)}  \n    for name in names:  \n        ele = ['.'] + [c for c in name] + ['.']  \n        for ch1, ch2 in zip(ele, ele[1:]):  \n            N[stoi[ch1], stoi[ch2]] += 1  \n    return N, itos, stoi  \n  \n  \ndef build_bigram_probability_with_smoothing(N):  \n    smoothed = N + torch.ones(1)  \n    row_sums = smoothed.sum(dim=1, keepdim=True)  \n    prob_matrix = smoothed / row_sums  \n    return prob_matrix  \n  \ndef generate_words(prob_matrix: torch.tensor, itos: str, num_words: int) -> List[str]:  \n    def dfs(i, cur_path, prob_matrix):  \n        if i == 0 and len(cur_path) > 0:  \n            return cur_path  \n        dist = torch.distributions.Categorical(prob_matrix[i])  \n        next_i = dist.sample((1,)).item()  \n        return dfs(next_i, cur_path + [next_i], prob_matrix)  \n  \n    out = []  \n    for _ in range(num_words):  \n        path = dfs(0, [], prob_matrix)  \n        word = \"\".join([itos[ele] for ele in path])  \n        out.append(word)  \n    return out  \n  \n  \nN, itos, stoi = name_to_bigram(filename)  \nprob_matrix = build_bigram_probability_with_smoothing(N)  \nword_lst = generate_words(prob_matrix, itos, num_words=10)  \nprint(word_lst)\n"})}),"\n",(0,i.jsx)(e.p,{children:"output:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"['n.', 'deiten.', 'avylod.', 'a.', 'bdrinn.', 'aarie.', 'ee.', 'kalalyah.', 'ke.', 'asla.']\n"})}),"\n",(0,i.jsx)(e.h1,{id:"\u7b2c2\u90e8\u5206-\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u62df\u5408-bigram-\u6a21\u578b\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d",children:"\u7b2c2\u90e8\u5206\uff1a \u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u62df\u5408 Bigram \u6a21\u578b\uff08\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\uff09"}),"\n",(0,i.jsxs)(e.p,{children:["\u672c\u7ec3\u4e60\u76ee\u6807\u662f\uff1a\u4e0d\u518d\u4f9d\u8d56\u7edf\u8ba1\u8ba1\u6570\u6784\u9020 bigram \u6982\u7387\u77e9\u9635\uff0c\u800c\u662f\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u4e0e\u68af\u5ea6\u4e0b\u964d ",(0,i.jsx)(e.strong,{children:"\u76f4\u63a5\u5b66\u4e60\u6240\u6709\u53c2\u6570"}),"\u3002"]}),"\n",(0,i.jsx)(e.p,{children:"\u6211\u4eec\u5c06\u9010\u6b65\u6784\u5efa\u4e00\u4e2a\u7b80\u5316\u7684 Bigram \u8bed\u8a00\u6a21\u578b\u3002\u6700\u7ec8\u76ee\u6807\u662f\uff1a"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:["\u5229\u7528\u795e\u7ecf\u7f51\u7edc ",(0,i.jsx)(e.code,{children:"W"}),"\uff0c\u8f93\u5165\u4e00\u4e2a\u5b57\u7b26\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5b57\u7b26\u7684\u6982\u7387\u5206\u5e03\u3002"]}),"\n",(0,i.jsx)(e.li,{children:"\u4f7f\u7528\u8d1f\u5bf9\u6570\u4f3c\u7136\u51fd\u6570\uff08Negative Log Likelihood\uff09\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u3002"}),"\n",(0,i.jsx)(e.li,{children:"\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u53c2\u6570\u3002"}),"\n"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"-\u9898\u76ee\u603b\u89c8",children:"\ud83e\udde9 \u9898\u76ee\u603b\u89c8"}),"\n",(0,i.jsx)(e.p,{children:"\u6211\u4eec\u5c06\u5b9e\u73b0\u4ee5\u4e0b\u5185\u5bb9\uff1a"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["\ud83d\udcca \u6570\u636e\u51c6\u5907\uff1a\u5c06\u5b57\u7b26 (",(0,i.jsx)(e.code,{children:"a"}),", ",(0,i.jsx)(e.code,{children:"b"}),", etc.) \u7f16\u7801\u4e3a one-hot \u5411\u91cf X\uff0c\u5e76\u5c06\u76ee\u6807\u5b57\u7b26\u7f16\u7801\u4e3a y\u3002"]}),"\n",(0,i.jsxs)(e.li,{children:["\ud83e\udde0 \u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff1a\u7528\u4e00\u5c42\u7ebf\u6027\u5c42 ",(0,i.jsx)(e.code,{children:"W"})," \u8fdb\u884c\u8bad\u7ec3\uff0c\u4f18\u5316\u6982\u7387\u9884\u6d4b\u3002"]}),"\n",(0,i.jsx)(e.li,{children:"\ud83c\udfaf \u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff1a\u4f7f\u7528\u8d1f\u5bf9\u6570\u4f3c\u7136\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u8fed\u4ee3\u4f18\u5316\u53c2\u6570\u3002"}),"\n",(0,i.jsx)(e.li,{children:"\u2705 \u9a8c\u8bc1\u6a21\u578b\u8f93\u51fa\u6982\u7387\u662f\u5426\u5408\u7406\uff0c\u8bc4\u4f30\u635f\u5931\u3002"}),"\n",(0,i.jsx)(e.li,{children:"\ud83e\uddea \u57fa\u4e8e\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u751f\u6210\u540d\u5b57\u3002"}),"\n",(0,i.jsx)(e.li,{children:"\ud83d\udee1\ufe0f \u6dfb\u52a0\u6b63\u5219\u5316\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\u3002"}),"\n"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"-\u9898\u76ee-1\u51c6\u5907\u8bad\u7ec3\u6570\u636ex-\u548c-y",children:"\ud83e\uddea \u9898\u76ee 1\uff1a\u51c6\u5907\u8bad\u7ec3\u6570\u636e\uff08X \u548c y\uff09"}),"\n",(0,i.jsx)(e.h3,{id:"-\u9898\u76ee\u63cf\u8ff0",children:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsxs)(e.p,{children:["\u4ece ",(0,i.jsx)(e.code,{children:"names.txt"})," \u4e2d\u8bfb\u53d6\u82f1\u6587\u540d\u5b57\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u540d\u5b57\u751f\u6210\u6240\u6709\u53ef\u80fd\u7684 bigram\uff08\u4e8c\u5b57\u7ec4\u5408\uff09\uff0c\u5c06\u7b2c\u4e00\u4e2a\u5b57\u7b26\u6620\u5c04\u4e3a one-hot \u7f16\u7801 X\uff0c\u7b2c\u4e8c\u4e2a\u5b57\u7b26\u6620\u5c04\u4e3a\u76ee\u6807\u6807\u7b7e y\u3002"]}),"\n",(0,i.jsx)(e.h3,{id:"-\u8f93\u5165\u793a\u4f8b",children:"\ud83d\udce5 \u8f93\u5165\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"names = ['emma']\n"})}),"\n",(0,i.jsx)(e.h3,{id:"-\u8f93\u51fa\u793a\u4f8b",children:"\ud83d\udce4 \u8f93\u51fa\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"X.shape = (4, 27)\ny.shape = (4, 27)\n"})}),"\n",(0,i.jsx)(e.h3,{id:"-\u51fd\u6570\u7b7e\u540d",children:"\ud83e\uddfe \u51fd\u6570\u7b7e\u540d\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def prepare_bigram_data(names: List[str]) -> Tuple[torch.Tensor, torch.Tensor]:\n"})}),"\n",(0,i.jsx)(e.h3,{id:"-\u6d4b\u8bd5\u7528\u4f8b",children:"\u2705 \u6d4b\u8bd5\u7528\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"X, y = prepare_bigram_data(['emma', 'jane'])\nassert X.shape[1] == 27\nassert X.shape == y.shape\n"})}),"\n",(0,i.jsx)(e.h3,{id:"implementation-4",children:"Implementation\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def prepare_bigram_data(names: List[str]) -> Tuple[torch.Tensor, torch.Tensor]:  \n    x_data = []  \n    y_data = []  \n    for name in names:  \n        ele = '.' + name + '.'  \n        for c1, c2 in zip(ele, ele[1:]):  \n            x_data.append(stoi[c1])  \n            y_data.append(stoi[c2])  \n    X = F.one_hot(torch.tensor(x_data), num_classes=len(itos))  \n    y = F.one_hot(torch.tensor(y_data), num_classes=len(itos))  \n    return X, y  \n  \nX, y = prepare_bigram_data(['emma', 'jane'])  \nprint(X.shape, y.shape)\n# torch.Size([10, 27]) torch.Size([10, 27])\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"-\u9898\u76ee-2\u6570\u636e\u96c6\u5212\u5206train-test-split",children:"\ud83e\uddea \u9898\u76ee 2\uff1a\u6570\u636e\u96c6\u5212\u5206\uff08Train-Test Split\uff09"}),"\n",(0,i.jsx)(e.h3,{id:"-\u9898\u76ee\u63cf\u8ff0-1",children:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsx)(e.p,{children:"\u5c06\u8bad\u7ec3\u6570\u636e\u6309 9:1 \u6bd4\u4f8b\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002\u4f60\u9700\u8981\u786e\u4fdd\uff1a"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u5212\u5206\u540e\u7684\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u603b\u957f\u5ea6\u4e0e\u539f\u59cb\u6570\u636e\u76f8\u540c"}),"\n",(0,i.jsx)(e.li,{children:"\u5212\u5206\u6bd4\u4f8b\u5c3d\u53ef\u80fd\u63a5\u8fd1 9:1"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-\u8f93\u5165",children:"\ud83d\udce5 \u8f93\u5165\uff1a"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"X: \u8f93\u5165\u7279\u5f81\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a (N, D)"}),"\n",(0,i.jsx)(e.li,{children:"y: \u6807\u7b7e\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a (N, D)"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-\u8f93\u51fa",children:"\ud83d\udce4 \u8f93\u51fa\uff1a"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"X_train, y_train, X_test, y_test"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-\u51fd\u6570\u7b7e\u540d-1",children:"\ud83e\uddfe \u51fd\u6570\u7b7e\u540d\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def train_test_split(X: torch.Tensor, y: torch.Tensor, ratio: float = 0.9) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n"})}),"\n",(0,i.jsx)(e.h3,{id:"-\u6d4b\u8bd5\u7528\u4f8b-1",children:"\u2705 \u6d4b\u8bd5\u7528\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"X = torch.randn(1000, 27)\ny = torch.randint(1000, 27)\nX_train, y_train, X_test, y_test = train_test_split(X, y)\n\nassert len(X_train) + len(X_test) == len(X)\nassert abs(len(X_train) / len(X) - 0.9) < 0.05  # \u5141\u8bb8\u6d6e\u52a8\u8bef\u5dee\nassert X_train.shape[1] == X.shape[1]\n"})}),"\n",(0,i.jsx)(e.h3,{id:"-implementation",children:"\u2705 Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import torch\nfrom typing import List, Tuple\ndef train_test_split(X: torch.Tensor, y: torch.Tensor, ratio: float = 0.9) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    size = X.size(0)\n    idx = torch.randperm(size)\n    X, y = X[idx], y[idx]\n    split = int(size*ratio)\n    X_train = X[:split, :]\n    y_train = y[:split, :]\n    X_test = X[split:, :]\n    y_test = y[split:, :]\n    return X_train, y_train, X_test, y_test\n\nprobs = torch.full((1000, 27), 0.5)  \nX = torch.bernoulli(probs)\ny = torch.bernoulli(probs)\nX_train, y_train, X_test, y_test = train_test_split(X, y)\nprint(X_train.size())\nprint(y_train.size())\nprint(X_test.size())\nprint(y_test.size())\nassert len(X_train) + len(X_test) == len(X)\nassert abs(len(X_train) / len(X) - 0.9) < 0.05  # \u5141\u8bb8\u6d6e\u52a8\u8bef\u5dee\nassert X_train.shape[1] == X.shape[1]\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"-\u9898\u76ee-3\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u5e76\u8bad\u7ec3",children:"\ud83e\uddea \u9898\u76ee 3\uff1a\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u5e76\u8bad\u7ec3"}),"\n",(0,i.jsx)(e.h3,{id:"-\u9898\u76ee\u63cf\u8ff0-2",children:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsxs)(e.p,{children:["\u6784\u5efa\u4e00\u4e2a\u7b80\u5355\u7684\u4e00\u5c42\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7528\u53c2\u6570\u77e9\u9635 ",(0,i.jsx)(e.code,{children:"W: (27, 27)"}),"\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u5b66\u4e60\u5b57\u7b26\u6982\u7387\u5206\u5e03\u3002\u540c\u65f6\u8bb0\u5f55\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u7684\u635f\u5931\uff0c\u5e76\u5728\u6700\u540e\u7ed8\u56fe\u53ef\u89c6\u5316\u3002"]}),"\n",(0,i.jsx)(e.h3,{id:"-\u8f93\u5165-1",children:"\ud83d\udce5 \u8f93\u5165\uff1a"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"X_train: \u8bad\u7ec3\u96c6 one-hot \u7f16\u7801\uff0c\u5f62\u72b6\u4e3a (N_train, 27)"}),"\n",(0,i.jsx)(e.li,{children:"y_train: \u8bad\u7ec3\u96c6\u6807\u7b7e\u7d22\u5f15"}),"\n",(0,i.jsx)(e.li,{children:"X_test: \u6d4b\u8bd5\u96c6 one-hot \u7f16\u7801\uff0c\u5f62\u72b6\u4e3a (N_test, 27)"}),"\n",(0,i.jsx)(e.li,{children:"y_test: \u6d4b\u8bd5\u96c6\u6807\u7b7e\u7d22\u5f15"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-\u8f93\u51fa-1",children:"\ud83d\udce4 \u8f93\u51fa\uff1a"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u53c2\u6570\u77e9\u9635 W"}),"\n",(0,i.jsx)(e.li,{children:"\u6bcf\u8f6e\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u7684 loss \u66f2\u7ebf\u56fe"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"-implementation-1",children:"\u2705 Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import evaluate\n\ndef calc_metrics(y_pred, y_test):\n    accuracy_metrics = evaluate.load('accuracy')\n    precision_metrics = evaluate.load('precision')\n    recall_metrics = evaluate.load('recall')\n    f1_metrics = evaluate.load('f1')\n\n    accuracy = accuracy_metrics.compute(predictions=y_pred, references=y_test)\n    precision = precision_metrics.compute(predictions=y_pred, references=y_test, average='macro')\n    recall = recall_metrics.compute(predictions=y_pred, references=y_test, average='macro')\n    f1 = f1_metrics.compute(predictions=y_pred, references=y_test, average='macro')\n    return accuracy['accuracy'], precision['precision'], recall['recall'], f1['f1']\n\ndef calc_loss(logits, y_test):\n    loss_fn = nn.CrossEntropyLoss()\n    loss = loss_fn(input=logits, target=y_test)\n    return loss\n\n\ndef train_model(model, X_train, y_train, X_test, y_test):\n    loss_lst = []\n    train_metrics_lst = []\n    test_metrics_lst = []\n    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n    for i in range(1000):\n        logits = model(X_train)\n        optimizer.zero_grad()\n        loss = calc_loss(logits, y_train)\n        loss.backward()\n        optimizer.step()\n        loss_lst.append(loss.item())\n        if i%100 == 0:\n            y_pred_train = torch.argmax(logits, dim=-1)\n            train_metrics = calc_metrics(y_pred_train, y_train)\n            train_metrics_lst.append(train_metrics)\n\n            test_logits = model(X_test)\n            y_pred_test = torch.argmax(test_logits, dim=-1)\n            test_metrics = calc_metrics(y_pred_test, y_test)\n            test_metrics_lst.append(test_metrics)\n            print(f'iteration --------------- {i}')\n            print(f'{train_metrics=}')\n            print(f'{test_metrics=}')\n\n    return model, loss_lst, train_metrics_lst, test_metrics_lst\n\n\nmodel = nn.Linear(27, 27)\nmodel, loss_lst, train_metrics_lst, test_metrics_lst = train_model(model,X_train, y_train, X_test, y_test)\ntorch.save(model.state_dict(), 'bigram_model.pt')\nimport matplotlib.pyplot as plt\nplt.plot(loss_lst)\nplt.show()\n"})}),"\n",(0,i.jsx)(e.p,{children:"output:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"iteration --------------- 0\ntrain_metrics=(0.03171951629320463, 0.011106836680262437, 0.03779708162560037, 0.012607840781202325)\ntest_metrics=(0.046767477536708305, 0.012360380555270493, 0.04539707880141161, 0.013951125872985446)\niteration --------------- 100\ntrain_metrics=(0.22237752701735247, 0.05070434206793784, 0.06316789755961444, 0.04287854493688251)\ntest_metrics=(0.22380013149243919, 0.051152348653181655, 0.06386562638003221, 0.04353229494652799)\niteration --------------- 200\ntrain_metrics=(0.2270090731550521, 0.08111826176875549, 0.07072834932945675, 0.055528432193995475)\ntest_metrics=(0.22739425816348893, 0.08106071260887054, 0.07162403216105664, 0.05687672350826672)\niteration --------------- 300\ntrain_metrics=(0.2275788848249899, 0.09631596363589946, 0.07660073648174895, 0.06368240441316037)\ntest_metrics=(0.22857769011615164, 0.09892511828307905, 0.07774631633670105, 0.06592106347257744)\niteration --------------- 400\ntrain_metrics=(0.22766654815882648, 0.09655852042892342, 0.07798802587197978, 0.06450014729570573)\ntest_metrics=(0.22910365987289064, 0.0992384119456147, 0.07916491652291907, 0.0668546561409721)\niteration --------------- 500\ntrain_metrics=(0.22766654815882648, 0.09655852042892342, 0.07798802587197978, 0.06450014729570573)\ntest_metrics=(0.22910365987289064, 0.0992384119456147, 0.07916491652291907, 0.0668546561409721)\niteration --------------- 600\ntrain_metrics=(0.22766654815882648, 0.09655852042892342, 0.07798802587197978, 0.06450014729570573)\ntest_metrics=(0.22910365987289064, 0.0992384119456147, 0.07916491652291907, 0.0668546561409721)\niteration --------------- 700\ntrain_metrics=(0.22766654815882648, 0.09655852042892342, 0.07798802587197978, 0.06450014729570573)\ntest_metrics=(0.22910365987289064, 0.0992384119456147, 0.07916491652291907, 0.0668546561409721)\niteration --------------- 800\ntrain_metrics=(0.22766654815882648, 0.09655852042892342, 0.07798802587197978, 0.06450014729570573)\ntest_metrics=(0.22910365987289064, 0.0992384119456147, 0.07916491652291907, 0.0668546561409721)\niteration --------------- 900\ntrain_metrics=(0.22766654815882648, 0.09655852042892342, 0.07798802587197978, 0.06450014729570573)\ntest_metrics=(0.22910365987289064, 0.0992384119456147, 0.07916491652291907, 0.0668546561409721)\n"})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/202507032159170.png",alt:""})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"-\u9898\u76ee-4\u751f\u6210\u540d\u5b57",children:"\ud83e\uddea \u9898\u76ee 4\uff1a\u751f\u6210\u540d\u5b57"}),"\n",(0,i.jsx)(e.h3,{id:"-\u9898\u76ee\u63cf\u8ff0-3",children:"\ud83d\udcc4 \u9898\u76ee\u63cf\u8ff0\uff1a"}),"\n",(0,i.jsxs)(e.p,{children:["\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u53c2\u6570 ",(0,i.jsx)(e.code,{children:"W"}),"\uff0c\u57fa\u4e8e\u9884\u6d4b\u6982\u7387\u4ece\u6a21\u578b\u4e2d\u91c7\u6837\u5b57\u7b26\u5e8f\u5217\uff0c\u751f\u6210\u82e5\u5e72\u65b0\u540d\u5b57\u3002"]}),"\n",(0,i.jsx)(e.h3,{id:"-\u8f93\u51fa\u793a\u4f8b-1",children:"\ud83d\udce4 \u8f93\u51fa\u793a\u4f8b\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"['emma.', 'joey.', 'marc.', 'lily.', 'zoe.']\n"})}),"\n",(0,i.jsx)(e.h3,{id:"-\u51fd\u6570\u7b7e\u540d-2",children:"\ud83e\uddfe \u51fd\u6570\u7b7e\u540d\uff1a"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"def generate_bigram_names(W: torch.Tensor, num_names: int) -> List[str]:\n"})}),"\n",(0,i.jsx)(e.h3,{id:"-implementation-2",children:"\u2705 Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"model = nn.Linear(27,27)\nstate_dict = torch.load('bigram_model.pt')\nmodel.load_state_dict(state_dict)\n\nimport random\ndef generate_bigram_names(model, num_names):\n    for _ in range(num_names):\n        start = random.randint(0, 26)\n        name = generate_name(model, [start])\n        print(name)\n\n\ndef generate_name(model, cur_i_lst):\n    if cur_i_lst[-1] == 0:\n        return \"\".join(itos[ele] for ele in cur_i_lst)\n    prev = F.one_hot(torch.tensor(cur_i_lst[-1]), num_classes=27).float()\n    logits = model(prev)\n    probs = F.softmax(logits)\n    dist = torch.distributions.Categorical(probs=probs)\n    sample = dist.sample((1,)).item()\n    cur_i_lst.append(sample)\n    return generate_name(model, cur_i_lst)\n\ngenerate_bigram_names(model, 20)\n"})}),"\n",(0,i.jsx)(e.p,{children:"Output:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"gadusetr.\nceyn.\nfaynsaynayl.\nmobannamahah.\ndi.\nwahathamiyn.\nkane.\nllaare.\numaruiuridyngrmaasha.\nmaia.\npe.\nha.\ncaarin.\nz.\ndron.\nle.\nsiasesoumientrh.\nwa.\njitosa.\numarnniechatzisaricca.\n"})}),"\n",(0,i.jsx)(e.p,{children:"\u6709\u8da3\u7684\u662f\uff0c\u5982\u679c\u6211\u6bcf\u6b21\u53d6argmax\uff0c\u800c\u4e0d\u662f\u6839\u636edistribution\uff0c\u5219\u53ea\u80fd\u51fa\u6765\u8fd9\u6837\u7684"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"bri.\na.\ni.\nja.\na.\ni.\nx.\nka.\nh.\nn.\nde.\non.\nh.\nja.\nya.\nush.\nca.\nush.\nya.\nn.\n"})}),"\n",(0,i.jsx)(e.h1,{id:"comparing-the-prob-matrix-and-the-weights",children:"Comparing the prob matrix and the weights"}),"\n",(0,i.jsx)(e.p,{children:"prob matrix (transposed):"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import matplotlib.pyplot as plt  \nimport numpy as np  \nplt.imshow(np.log(prob_matrix).transpose(0,1), cmap='grey')  \nplt.colorbar()  \nplt.xticks(ticks=np.arange(27), labels=itos)  \nplt.yticks(ticks=np.arange(27), labels=itos)  \n  \nplt.show()\n"})}),"\n",(0,i.jsxs)(e.p,{children:["bigram model weights (I used ",(0,i.jsx)(e.code,{children:"nn.Linear(27, 27, bias=False))"})," to initialize this time)"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"import matplotlib.pyplot as plt  \nimport numpy as np  \nplt.plot(loss_lst)  \nplt.show()  \n  \nmodel = nn.Linear(27,27)  \nstate_dict = torch.load('bigram_model.pt')  \nweight = state_dict['weight']  \n  \n# plt.figure(figsize=(50,50))  \nplt.imshow(weight, cmap='grey')  \nplt.colorbar()  \nplt.xticks(ticks=np.arange(27), labels=itos)  \nplt.yticks(ticks=np.arange(27), labels=itos)  \n  \nplt.show()\n"})}),"\n",(0,i.jsx)(e.p,{children:"Left is prob matrix transposed, taking log, right is bigram model weights. They are very similar."}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{src:"https://raw.githubusercontent.com/emmableu/image/master/202507032211026.png",alt:""})}),"\n",(0,i.jsx)(e.p,{children:"\u2705 1. \u4e24\u56fe\u975e\u5e38\u76f8\u4f3c"}),"\n",(0,i.jsx)(e.p,{children:"\u2705 2. \u67d0\u4e9b\u5217\u63a5\u8fd1\u5168\u9ed1\uff08\u5982 q\uff09"}),"\n",(0,i.jsx)(e.p,{children:"\u8bf4\u660e 'q' \u4f5c\u4e3a\u524d\u7f00\u5b57\u7b26\u7f55\u89c1\uff0c\u53ea\u6709 'q' \u2192 'u' \u4eae\u4e00\u70b9\uff0c\u5176\u4ed6\u51e0\u4e4e\u4e0d\u53ef\u8fbe\u3002"}),"\n",(0,i.jsx)(e.p,{children:"\u2705 3. \u67d0\u4e9b\u822a\u7279\u522b\u4eae\uff08\u5982 .\uff0ca\uff0ce\uff0ci\uff0co\uff09"}),"\n",(0,i.jsx)(e.p,{children:"\u8fd9\u4e9b\u5b57\u7b26\u7ecf\u5e38\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u5b57\u7b26\u51fa\u73b0\uff0c\u662f\u5f88\u591a bigram \u7684\u76ee\u6807\u5b57\u7b26\u3002"}),"\n",(0,i.jsx)(e.p,{children:"\u2705 4. \u5b58\u5728\u9ad8\u4eae\u5b50\u5757\uff08\u5982 qu\uff0ccr\uff0c br\uff09"}),"\n",(0,i.jsx)(e.p,{children:"\u5bf9\u5e94\u8bed\u8a00\u4e2d\u7684\u9ad8\u9891\u4e8c\u5143\u7ec4\u5408\u3002"}),"\n",(0,i.jsx)(e.h1,{id:"appendix",children:"Appendix:"}),"\n",(0,i.jsx)(e.h3,{id:"example-1-concatenating-2d-tensors",children:"Example 1: Concatenating 2D Tensors"}),"\n",(0,i.jsx)(e.p,{children:"Let's start with a simple example of concatenating two 2D tensors along different dimensions."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'pythonCopy code\nimport torch\n\n# Create two 2D tensors\ntensor1 = torch.tensor([[1, 2, 3],\n                        [4, 5, 6]])\n\ntensor2 = torch.tensor([[7, 8, 9],\n                        [10, 11, 12]])\n\nprint("Tensor 1:")\nprint(tensor1)\n\nprint("Tensor 2:")\nprint(tensor2)\n\n'})}),"\n",(0,i.jsxs)(e.h3,{id:"concatenate-alongdim0rows---means-expanding-on-number-of-rows",children:[(0,i.jsxs)(e.strong,{children:["Concatenate along\xa0",(0,i.jsx)(e.code,{children:"dim=0"})]}),"\xa0(rows): - means expanding on number of rows."]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'pythonCopy code\nresult_dim0 = torch.cat((tensor1, tensor2), dim=0)\nprint("Concatenate along dim=0:")\nprint(result_dim0)\n'})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Output:"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"plaintextCopy code\ntensor([[ 1,  2,  3],\n        [ 4,  5,  6],\n        [ 7,  8,  9],\n        [10, 11, 12]])\n\n"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Explanation"}),": Concatenating along\xa0",(0,i.jsx)(e.code,{children:"dim=0"}),"\xa0adds the rows of\xa0",(0,i.jsx)(e.code,{children:"tensor2"}),"\xa0below the rows of\xa0",(0,i.jsx)(e.code,{children:"tensor1"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(e.h3,{id:"concatenate-alongdim1columns",children:[(0,i.jsxs)(e.strong,{children:["Concatenate along\xa0",(0,i.jsx)(e.code,{children:"dim=1"})]}),"\xa0(columns):"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'pythonCopy code\nresult_dim1 = torch.cat((tensor1, tensor2), dim=1)\nprint("Concatenate along dim=1:")\nprint(result_dim1)\n\n'})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Output:"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"plaintextCopy code\ntensor([[ 1,  2,  3,  7,  8,  9],\n        [ 4,  5,  6, 10, 11, 12]])\n\n"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Explanation"}),": Concatenating along\xa0",(0,i.jsx)(e.code,{children:"dim=1"}),"\xa0adds the columns of\xa0",(0,i.jsx)(e.code,{children:"tensor2"}),"\xa0to the right of the columns of\xa0",(0,i.jsx)(e.code,{children:"tensor1"}),"."]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}}}]);