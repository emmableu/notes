<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-ML General/T-SNE or tSNE or tsne" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">T-SNE or tSNE or tsne | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://emmableu.github.io/notes/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://emmableu.github.io/notes/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://emmableu.github.io/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="T-SNE or tSNE or tsne | My Site"><meta data-rh="true" name="description" content="Definition:"><meta data-rh="true" property="og:description" content="Definition:"><link data-rh="true" rel="icon" href="/notes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://emmableu.github.io/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad"><link data-rh="true" rel="alternate" href="https://emmableu.github.io/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad" hreflang="en"><link data-rh="true" rel="alternate" href="https://emmableu.github.io/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"05. ML General","item":"https://emmableu.github.io/notes/docs/ml-general"},{"@type":"ListItem","position":2,"name":"T-SNE or tSNE or tsne","item":"https://emmableu.github.io/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad"}]}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous"><link rel="stylesheet" href="/notes/assets/css/styles.607fdee8.css">
<script src="/notes/assets/js/runtime~main.c02a6fe4.js" defer="defer"></script>
<script src="/notes/assets/js/main.02311e79.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes/"><div class="navbar__logo"><img src="/notes/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/notes/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/notes/docs/ml100">01. ML Theory 100</a><a class="navbar__item navbar__link" href="/notes/docs/dl100">02. DL Theory 100</a><a class="navbar__item navbar__link" href="/notes/docs/leetcode">03. Leetcode</a><a class="navbar__item navbar__link" href="/notes/docs/zero2hero">04. Zero To Hero</a><a class="navbar__item navbar__link" href="/notes/docs/ml-general">05. ML General</a><a class="navbar__item navbar__link" href="/notes/docs/reinforcement-learning">Reinforcement Learning</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/ml100">01. ML Theory 100</a><button aria-label="Expand sidebar category &#x27;01. ML Theory 100&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/notes/docs/ml-general">05. ML General</a><button aria-label="Collapse sidebar category &#x27;05. ML General&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/cc9e9b72-f558-45fb-b323-8c982cd21785">ML资源</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6a1a76f4-1db9-459d-a3ff-6d9fb9bd3c8e">Likelihood Basics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/33322e19-551a-47dd-ba82-e1a9d5d30479">Bias and Variance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/40c27ac6-55a8-4fa7-94a2-9e0ea4b0976d">Classification Metric</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/780d6a08-9052-48b8-be65-8e0aa46e3ffb">Feature Selection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/74afc8cf-1b32-4848-b8ca-8a61fa8f137b">Regularization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/ab96da11-1590-44aa-801a-2848affaa604">Distributions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e66fc711-ed04-4037-9657-70f91790966b">Mutual Information</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/85996f78-63d2-4da1-b968-385104020c3c">Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/b026b72a-d550-4301-8b1d-c443c79d9e0c">Logistic Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/78d7a94f-b5a8-4b20-a94f-643f772a6ee2">Decision Tree</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e7292d95-c582-4cb3-85ef-1adc73b3a172">Ensemble Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/2784b330-5a5e-449f-9a0e-27da46d5c017">Naive Bayes and Generative Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/d7874b72-4d46-49c8-9996-4b65598d8ed8">Linear Discrimitive Analysis (LDA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e4b13962-3bfd-4179-9f05-8389360f76b6">Support Vector Machine (SVM)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/bc2360e2-3cde-44dd-ad53-b5cddfd713e7">Hierarchical Clustering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/c8f4884e-488f-4566-8b4d-690d0e062362">EM Algorithm</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/bdee33c5-59c5-4656-ae24-de6a44a339c6">KNN - K Nearest Neighbor</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/83bf409d-c62d-436f-8814-d1bcd2c739ff">SoftMax and Cross-Entropy Loss Function</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/75f6131c-e9cb-4073-b06a-407ca559b982">Principle Component Analysis - PCA</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/3950ea5b-4dcb-4513-804d-55d0162005c8">Learning to Rank</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/75d0bf4d-fcc2-4e72-b273-4e862d8898f8">GMM - Gaussian Mixed Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8">Gradient Boost 细节</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad">T-SNE or tSNE or tsne</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/5e97f5b9-0ff7-4097-9053-526db6d75222">Convexity, local, global minima</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/9568038f-e88e-4df3-a806-5532f48cef35">Neural Network Intro</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6a021dfe-ba24-4fd3-8e3d-548e660e5a08">Gradient Descent (Best Explanation)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/af31081f-3337-4f01-9762-7eb2d9c9001d">Backpropagation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/39005b9b-0dc7-477a-b12b-ab99967780db">Multiple Inputs and Outputs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/b3253a65-5a0a-4717-8a41-a7b6dd377834">Loss Functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6a1c56e8-94cf-4eff-9f46-a60b6a34f55e">Batch Normalization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/1c3d3e83-cba5-490e-adac-bbffd4d7c2c9">Dropout</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/06ca38e7-caea-4560-a877-a72fa1e06183">PyTorch - Convolutional Neural Network (CNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/fca7bec5-0756-4298-ac4c-46b13422b565">Recurrent Neural Network - RNN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/cdf7bcb9-c32f-4124-a4c9-f65f76c1a69d">LSTM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/fbab20b7-b47f-4dcd-a022-b9926965e147">BERT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/016d741d-2e5f-4c42-89e2-3b5732ccaae8">GAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6b0d6c51-2d88-4110-ba81-9b78d4a2ce9c">ResNet 残差网络</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/2e942169-193e-4a5a-838f-61ff2df5f9b4">Encoder-Decoder 编码器-解码器</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/a8b31f8a-3b38-4a19-a18b-5625ba34d1b6">百面机器学习 - 答案 Bai Mian Baimian Solution</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e087fb01-09b6-4fee-8ae0-8a70e379d71b">Definition Glossary</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/70a87f0a-d0f2-4e2d-a3a5-c7eb19daa4b3">评价模型 Model Review</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/56af319b-39c9-41e1-959a-0e470b51ffc0">Model Compare 比较模型好坏</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/97e0f4a6-4e81-49c1-8216-28e411710e65">DBSCAN</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/dl100">02. DL Theory 100</a><button aria-label="Expand sidebar category &#x27;02. DL Theory 100&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/leetcode">03. Leetcode</a><button aria-label="Expand sidebar category &#x27;03. Leetcode&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/zero2hero">04. Zero to Hero</a><button aria-label="Expand sidebar category &#x27;04. Zero to Hero&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/reinforcement-learning">Reinforcement Learning</a><button aria-label="Expand sidebar category &#x27;Reinforcement Learning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes/docs/docs">Docs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes/docs/docs/intro">Welcome / Placeholder</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/notes/docs/ml-general"><span>05. ML General</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">T-SNE or tSNE or tsne</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>T-SNE or tSNE or tsne</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="definition">Definition:<a href="#definition" class="hash-link" aria-label="Direct link to Definition:" title="Direct link to Definition:">​</a></h2>
<ul>
<li>What t-SNE does is find a way to project data into a low dimensional space, so that the clustering in the high dimensional space is preserved</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="process">process<a href="#process" class="hash-link" aria-label="Direct link to process" title="Direct link to process">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202210061845422.png" alt="" class="img_ev3q"></p>
<ol>
<li>we start with putting the points to random points in low dimensional space (on the line)</li>
<li>at each step, a point in the new dimensional space (on the line) is attracted to points it is near in the original space (the scatter point), and repelled by points it is far from.</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="detailed-process">detailed process<a href="#detailed-process" class="hash-link" aria-label="Direct link to detailed process" title="Direct link to detailed process">​</a></h2>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-t-sne-works">How t-SNE works?<a href="#how-t-sne-works" class="hash-link" aria-label="Direct link to How t-SNE works?" title="Direct link to How t-SNE works?">​</a></h2>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="probability-distribution">Probability Distribution<a href="#probability-distribution" class="hash-link" aria-label="Direct link to Probability Distribution" title="Direct link to Probability Distribution">​</a></h2>
<p>Let’s start with <strong>SNE</strong> part of t-SNE. I’m far better with explaining things visually so this is going to be our dataset:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*NYve_va3wHU4zNnj.png" alt="" class="img_ev3q"></p>
<p>It has 3 different classes and you can easily distinguish them from each other. The first part of the algorithm is to create a <strong>probability distribution</strong> that represents similarities between neighbors. What is “similarity”? <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="noopener noreferrer">Original paper</a> states “ <strong>similarity of datapoint</strong> xⱼ <strong>to datapoint</strong> xᵢ <strong>is the conditional probability</strong> p_{j|i}<strong>, that</strong> xᵢ <strong>would pick</strong> xⱼ <strong>as its neighbor</strong> “.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*ETuCH0wXgSyit1i3.png" alt="" class="img_ev3q"></p>
<p>We’ve picked one of the points from the dataset. Now we have to pick another point and calculate Euclidean Distance between them |xᵢ — xⱼ|</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*g1bTTv6Wu632piCu.png" alt="" class="img_ev3q"></p>
<p>The next part of the original paper states that it has to be <strong>proportional to probability density under a Gaussian centered at</strong> xᵢ. So we have to generate Gaussian distribution with mean at xᵢ_,_ and place our distance on the X-axis.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*j6P77qstfwQ6mkT8.png" alt="" class="img_ev3q"></p>
<p>Right now you might wonder about <em>σ²</em> (variance) and that’s a good thing. But let’s just ignore it for now and assume I’ve already decided what it should be. After calculating the first point we have to do the same thing for every single point out there.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*Afr8xsKrl6dwZ10Q.png" alt="" class="img_ev3q"></p>
<p>You might think, we’re already done with this part. But that’s just the beginning.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scattered-clusters-and-variance">Scattered clusters and variance<a href="#scattered-clusters-and-variance" class="hash-link" aria-label="Direct link to Scattered clusters and variance" title="Direct link to Scattered clusters and variance">​</a></h2>
<p>Up to this point, our clusters were tightly bounded within its group. What if we have a new cluster like that:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*nZrA0hPQqM1Ce7-j.png" alt="" class="img_ev3q"></p>
<p>We should be able to apply the same process as before, shouldn’t we?</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*0MzS6wydzd5Dr02Y.png" alt="" class="img_ev3q"></p>
<p>We’re still not done. You can distinguish between similar and non-similar points but absolute values of probability are much smaller than in the first example (compare Y-axis values).</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*kpctqZwCMDkqJK3u.png" alt="" class="img_ev3q"></p>
<p>We can fix that by dividing the current projection value by the sum of the projections.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/526/1*1gBOzGPwWEN4L_HhYLN-VQ.png" alt="" class="img_ev3q"></p>
<p>Which if you apply to the first example will look sth like:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1228/1*r3tuMMndpFZswRfIVNCEaw.png" alt="" class="img_ev3q"></p>
<p>And for the second example:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1262/1*9XfcJTE-gFjGxFgdqOQKsQ.png" alt="" class="img_ev3q"></p>
<p>This scales all values to have a sum equal to 1. It’s a good place to mention that p_{i|i}​ is set to be equal to 0, not 1.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/228/1*2oCxcLq7hvxQcrjmFiClMA.png" alt="" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dealing-with-different-distances">Dealing with different distances<a href="#dealing-with-different-distances" class="hash-link" aria-label="Direct link to Dealing with different distances" title="Direct link to Dealing with different distances">​</a></h2>
<p>If we take two points and try to calculate conditional probability between them then values of p_{i|j}​ and p_{j|i}​ will be different:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*pTTqRArwYV_tGnF0.png" alt="" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*-JXLaDNYjjSSGVdf.png" alt="" class="img_ev3q"></p>
<p>The reason for that is because they are coming from two different distributions. Which one should we pick to the calculation then?</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/336/1*gFbUxuUZlcRhIzYXvYzUCA.png" alt="" class="img_ev3q"></p>
<p>Where <em>N</em> is a number of dimensions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-lie-">The lie :)<a href="#the-lie-" class="hash-link" aria-label="Direct link to The lie :)" title="Direct link to The lie :)">​</a></h2>
<p>Now when we have everything scaled to 1 (yes, the sum of all equals 1), I can tell you that I wasn’t completely honest about while the process with you :) Calculation all of that would be quite painful for the algorithm and that’s not what exactly is in <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="noopener noreferrer">t-SNE paper</a>.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/736/1*J4lRX3F6qR9TF9VgH6Vd1Q.png" alt="" class="img_ev3q"></p>
<p>This is an original formula to calculate p_{j|i}. Why did I lie to you? First, because it’s easier to get an intuition about how it works. Second, because I was going to show you the trough either way.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="perplexity">Perplexity<a href="#perplexity" class="hash-link" aria-label="Direct link to Perplexity" title="Direct link to Perplexity">​</a></h2>
<p>If you look at this formula. You can spot that our</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/226/1*2q0ECctHTmnbCop71LlJOQ.png" alt="" class="img_ev3q"></p>
<p>is</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/446/1*3_qQH7KjQR89ymcDk0Y5Yw.png" alt="" class="img_ev3q"></p>
<p>If I would show you this straight away, it would be hard to explain where <em>σ²</em> is coming from and what is a dependency between it and our clusters. Now you know that variance depends on Gaussian and the number of points surrounding the center of it. This is the part where <strong>perplexity</strong> value comes. A perplexity is more or less a target number of neighbors for our central point. Basically, the higher the perplexity is the higher value variance has. Our “red” group is close to each other and if we set perplexity to 4, it searches the right value of to “fit” our 4 neighbors. If you want to be more specific then you can quote the original paper:</p>
<blockquote>
<p><em>SNE performs a binary search for the value of sigma that produces probability distribution with a fixed perplexity that is specified by the user</em></p>
</blockquote>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/496/1*Csv1yl-2zOxC42wV-WGVkQ.png" alt="" class="img_ev3q"></p>
<p>Where</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/292/1*jhLo78eY9Jky4vMP42RC8Q.png" alt="" class="img_ev3q"></p>
<p>​ is <strong>Shannon entropy</strong>. But unless you want to implement t-SNE yourself, the only thing you need to know is that perplexity you choose is positively correlated with the value of \mu_i_μi_​ and for the same perplexity you will have multiple different \mu_i_μi_​, base on distances. Typical perplexity value ranges between 5 and 50.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="original-formula-interpretation">Original formula interpretation<a href="#original-formula-interpretation" class="hash-link" aria-label="Direct link to Original formula interpretation" title="Direct link to Original formula interpretation">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/736/1*J4lRX3F6qR9TF9VgH6Vd1Q.png" alt="" class="img_ev3q"></p>
<p>When you look on this formula you might notice that our Gaussian is converted into</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/436/1*xi6CUrwPLG4-1CZwt-hX0Q.png" alt="" class="img_ev3q"></p>
<p>Let me show you how that looks like:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*sNHrck20Xt7uS7X9.png" alt="" class="img_ev3q"></p>
<p>If you play with <em>σ²</em> for a while you can notice that the blue curve remains fixed at point <em>x</em>=0. It only stretches when <em>σ²</em> increases.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*SQWPC3TlgUqnsuSu.png" alt="" class="img_ev3q"></p>
<p>That helps distinguish neighbor’s probabilities and because you’ve already understood the whole process you should be able to adjust it to new values.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="create-low-dimensional-space">Create low-dimensional space<a href="#create-low-dimensional-space" class="hash-link" aria-label="Direct link to Create low-dimensional space" title="Direct link to Create low-dimensional space">​</a></h2>
<p>The next part of t-SNE is to create low-dimensional space with the same number of points as in the original space. Points should be spread randomly on a new space. The goal of this algorithm is to find similar probability distribution in low-dimensional space. The most obvious choice for new distribution would be to use Gaussian again. That’s not the best idea, unfortunately. One of the properties of Gaussian is that it has a “short tail” and because of that it creates a <strong>crowding problem</strong>. To solve that we’re going to use <strong>Student t-distribution</strong> with a single degree of freedom. More of how this distribution was selected and why Gaussian is not the best idea you can find in the <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="noopener noreferrer">paper</a>. I decided not to spend much time on it and allow you to read this article within a reasonable time. So now our new formula will look like:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/632/1*ZDiRzmCfK1xuCzldJ8-tvQ.png" alt="" class="img_ev3q"></p>
<p>instead of:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/690/1*Hax1tT4LMqH9RqUN4d7ulA.png" alt="" class="img_ev3q"></p>
<p>If you’re more “visual” person this might help (values on X-axis are distributed randomly):</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*z_xyrUJsAlkdKNjX.png" alt="" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*SEhDsFAK-qH6fLJv.png" alt="" class="img_ev3q"></p>
<p>Using Student distribution has exactly what we need. It “falls” quickly and has a “long tail” so points won’t get squashed into a single point. This time we don’t have to bother with <em>σ²</em> because we don’t have one in q_{ij} formula. I won’t generate the whole process of calculating q_{ij} because it works exactly the same as p_{ij}. Instead, just leave you with those two formulas and skip to sth more important:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/726/1*l4Gjd2F_cnZQDvSi6zlu1w.png" alt="" class="img_ev3q"></p>
<h1>Gradient descent</h1>
<p>To optimize this distribution t-SNE is using <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" target="_blank" rel="noopener noreferrer"><strong>Kullback-Leibler divergence</strong></a> between the conditional probabilities p_{j|i} and q_{j|i}</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/846/1*xi-IjvMSJmNu-jfHlZ0qvA.png" alt="" class="img_ev3q"></p>
<p>I’m not going through the math here because it’s not important. What we need is a derivate for (it’s derived in <strong>Appendix A</strong> inside the <a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" target="_blank" rel="noopener noreferrer">original paper</a>).</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/938/1*WK-kP2JJsAbYgw49hQENhA.png" alt="" class="img_ev3q"></p>
<p>You can treat that gradient as repulsion and attraction between points. A gradient is calculated for each point and describes how “strong” it should be pulled and the direction it should choose. If we start with our random 1D plane and perform gradient on the previous distribution it should look like this.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*gx5m_CS7gVUn8WLH.gif" alt="" class="img_ev3q"></p>
<p>Ofc. this is an exaggeration. t-SNE doesn’t run that quickly. I’ve just skipped a lot of steps in there to make it faster. Besides that, the values here are not completely correct, but it’s good enough to show you the process.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tricks-optimizations-done-in-t-sne-to-perform-better">Tricks (optimizations) done in t-SNE to perform better<a href="#tricks-optimizations-done-in-t-sne-to-perform-better" class="hash-link" aria-label="Direct link to Tricks (optimizations) done in t-SNE to perform better" title="Direct link to Tricks (optimizations) done in t-SNE to perform better">​</a></h2>
<p>t-SNE performs well on itself but there are some improvements allow it to do even better.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="early-compression">Early Compression<a href="#early-compression" class="hash-link" aria-label="Direct link to Early Compression" title="Direct link to Early Compression">​</a></h2>
<p>To prevent early clustering t-SNE is adding L2 penalty to the cost function at the early stages. You can treat it as standard regularization because it allows the algorithm not to focus on local groups.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="early-exaggeration">Early Exaggeration<a href="#early-exaggeration" class="hash-link" aria-label="Direct link to Early Exaggeration" title="Direct link to Early Exaggeration">​</a></h2>
<p>This trick allows moving clusters of (q_{ij}​) more. This time we’re multiplying p_{ij}​ in early stages. Because of that clusters don’t get in each other’s ways.</p>
<h1>Conclusions</h1>
<p>t-SNE is a great tool to understand high-dimensional datasets. It might be less useful when you want to perform dimensionality reduction for ML training (cannot be reapplied in the same way). It’s not deterministic and iterative so each time it runs, it could produce a different result. But even with that disadvantages it still remains one of the most popular method in the field.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/emmableu/notes/edit/main/docs/05. ML General/40.T-SNE or tSNE or tsne.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Gradient Boost 细节</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes/docs/p/5e97f5b9-0ff7-4097-9053-526db6d75222"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Convexity, local, global minima</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#definition" class="table-of-contents__link toc-highlight">Definition:</a></li><li><a href="#process" class="table-of-contents__link toc-highlight">process</a></li><li><a href="#detailed-process" class="table-of-contents__link toc-highlight">detailed process</a></li><li><a href="#how-t-sne-works" class="table-of-contents__link toc-highlight">How t-SNE works?</a></li><li><a href="#probability-distribution" class="table-of-contents__link toc-highlight">Probability Distribution</a></li><li><a href="#scattered-clusters-and-variance" class="table-of-contents__link toc-highlight">Scattered clusters and variance</a></li><li><a href="#dealing-with-different-distances" class="table-of-contents__link toc-highlight">Dealing with different distances</a></li><li><a href="#the-lie-" class="table-of-contents__link toc-highlight">The lie :)</a></li><li><a href="#perplexity" class="table-of-contents__link toc-highlight">Perplexity</a></li><li><a href="#original-formula-interpretation" class="table-of-contents__link toc-highlight">Original formula interpretation</a></li><li><a href="#create-low-dimensional-space" class="table-of-contents__link toc-highlight">Create low-dimensional space</a></li><li><a href="#tricks-optimizations-done-in-t-sne-to-perform-better" class="table-of-contents__link toc-highlight">Tricks (optimizations) done in t-SNE to perform better</a></li><li><a href="#early-compression" class="table-of-contents__link toc-highlight">Early Compression</a></li><li><a href="#early-exaggeration" class="table-of-contents__link toc-highlight">Early Exaggeration</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes/docs/intro">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/emmableu/notes" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>