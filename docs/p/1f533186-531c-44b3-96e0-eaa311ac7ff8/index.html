<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-ML General/Gradient Boost 细节" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Gradient Boost 细节 | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://emmableu.github.io/notes/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://emmableu.github.io/notes/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://emmableu.github.io/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Gradient Boost 细节 | My Site"><meta data-rh="true" name="description" content="Definition"><meta data-rh="true" property="og:description" content="Definition"><link data-rh="true" rel="icon" href="/notes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://emmableu.github.io/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8"><link data-rh="true" rel="alternate" href="https://emmableu.github.io/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8" hreflang="en"><link data-rh="true" rel="alternate" href="https://emmableu.github.io/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"05. ML General","item":"https://emmableu.github.io/notes/docs/ml-general"},{"@type":"ListItem","position":2,"name":"Gradient Boost 细节","item":"https://emmableu.github.io/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8"}]}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous"><link rel="stylesheet" href="/notes/assets/css/styles.607fdee8.css">
<script src="/notes/assets/js/runtime~main.c02a6fe4.js" defer="defer"></script>
<script src="/notes/assets/js/main.02311e79.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/notes/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/notes/"><div class="navbar__logo"><img src="/notes/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/notes/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">My Site</b></a><a class="navbar__item navbar__link" href="/notes/docs/ml100">01. ML Theory 100</a><a class="navbar__item navbar__link" href="/notes/docs/dl100">02. DL Theory 100</a><a class="navbar__item navbar__link" href="/notes/docs/leetcode">03. Leetcode</a><a class="navbar__item navbar__link" href="/notes/docs/zero2hero">04. Zero To Hero</a><a class="navbar__item navbar__link" href="/notes/docs/ml-general">05. ML General</a><a class="navbar__item navbar__link" href="/notes/docs/reinforcement-learning">Reinforcement Learning</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/ml100">01. ML Theory 100</a><button aria-label="Expand sidebar category &#x27;01. ML Theory 100&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/notes/docs/ml-general">05. ML General</a><button aria-label="Collapse sidebar category &#x27;05. ML General&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/cc9e9b72-f558-45fb-b323-8c982cd21785">ML资源</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6a1a76f4-1db9-459d-a3ff-6d9fb9bd3c8e">Likelihood Basics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/33322e19-551a-47dd-ba82-e1a9d5d30479">Bias and Variance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/40c27ac6-55a8-4fa7-94a2-9e0ea4b0976d">Classification Metric</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/780d6a08-9052-48b8-be65-8e0aa46e3ffb">Feature Selection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/74afc8cf-1b32-4848-b8ca-8a61fa8f137b">Regularization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/ab96da11-1590-44aa-801a-2848affaa604">Distributions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e66fc711-ed04-4037-9657-70f91790966b">Mutual Information</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/85996f78-63d2-4da1-b968-385104020c3c">Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/b026b72a-d550-4301-8b1d-c443c79d9e0c">Logistic Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/78d7a94f-b5a8-4b20-a94f-643f772a6ee2">Decision Tree</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e7292d95-c582-4cb3-85ef-1adc73b3a172">Ensemble Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/2784b330-5a5e-449f-9a0e-27da46d5c017">Naive Bayes and Generative Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/d7874b72-4d46-49c8-9996-4b65598d8ed8">Linear Discrimitive Analysis (LDA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e4b13962-3bfd-4179-9f05-8389360f76b6">Support Vector Machine (SVM)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/bc2360e2-3cde-44dd-ad53-b5cddfd713e7">Hierarchical Clustering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/c8f4884e-488f-4566-8b4d-690d0e062362">EM Algorithm</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/bdee33c5-59c5-4656-ae24-de6a44a339c6">KNN - K Nearest Neighbor</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/83bf409d-c62d-436f-8814-d1bcd2c739ff">SoftMax and Cross-Entropy Loss Function</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/75f6131c-e9cb-4073-b06a-407ca559b982">Principle Component Analysis - PCA</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/3950ea5b-4dcb-4513-804d-55d0162005c8">Learning to Rank</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/75d0bf4d-fcc2-4e72-b273-4e862d8898f8">GMM - Gaussian Mixed Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/notes/docs/p/1f533186-531c-44b3-96e0-eaa311ac7ff8">Gradient Boost 细节</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad">T-SNE or tSNE or tsne</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/5e97f5b9-0ff7-4097-9053-526db6d75222">Convexity, local, global minima</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/9568038f-e88e-4df3-a806-5532f48cef35">Neural Network Intro</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6a021dfe-ba24-4fd3-8e3d-548e660e5a08">Gradient Descent (Best Explanation)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/af31081f-3337-4f01-9762-7eb2d9c9001d">Backpropagation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/39005b9b-0dc7-477a-b12b-ab99967780db">Multiple Inputs and Outputs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/b3253a65-5a0a-4717-8a41-a7b6dd377834">Loss Functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6a1c56e8-94cf-4eff-9f46-a60b6a34f55e">Batch Normalization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/1c3d3e83-cba5-490e-adac-bbffd4d7c2c9">Dropout</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/06ca38e7-caea-4560-a877-a72fa1e06183">PyTorch - Convolutional Neural Network (CNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/fca7bec5-0756-4298-ac4c-46b13422b565">Recurrent Neural Network - RNN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/cdf7bcb9-c32f-4124-a4c9-f65f76c1a69d">LSTM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/fbab20b7-b47f-4dcd-a022-b9926965e147">BERT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/016d741d-2e5f-4c42-89e2-3b5732ccaae8">GAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/6b0d6c51-2d88-4110-ba81-9b78d4a2ce9c">ResNet 残差网络</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/2e942169-193e-4a5a-838f-61ff2df5f9b4">Encoder-Decoder 编码器-解码器</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/a8b31f8a-3b38-4a19-a18b-5625ba34d1b6">百面机器学习 - 答案 Bai Mian Baimian Solution</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/e087fb01-09b6-4fee-8ae0-8a70e379d71b">Definition Glossary</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/70a87f0a-d0f2-4e2d-a3a5-c7eb19daa4b3">评价模型 Model Review</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/56af319b-39c9-41e1-959a-0e470b51ffc0">Model Compare 比较模型好坏</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/notes/docs/p/97e0f4a6-4e81-49c1-8216-28e411710e65">DBSCAN</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/dl100">02. DL Theory 100</a><button aria-label="Expand sidebar category &#x27;02. DL Theory 100&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/leetcode">03. Leetcode</a><button aria-label="Expand sidebar category &#x27;03. Leetcode&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/zero2hero">04. Zero to Hero</a><button aria-label="Expand sidebar category &#x27;04. Zero to Hero&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/notes/docs/reinforcement-learning">Reinforcement Learning</a><button aria-label="Expand sidebar category &#x27;Reinforcement Learning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes/docs/docs">Docs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/notes/docs/docs/intro">Welcome / Placeholder</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/notes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/notes/docs/ml-general"><span>05. ML General</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Gradient Boost 细节</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Gradient Boost 细节</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="definition">Definition<a href="#definition" class="hash-link" aria-label="Direct link to Definition" title="Direct link to Definition">​</a></h2>
<p>gradient boosting:
- A training algorithm where weak models are trained to iteratively improve the quality (reduce the loss) of a strong model. For example, a weak model could be a linear or small decision tree model. The strong model becomes the sum of all the previously trained weak models.
- at each iteration, a weak model is trained to predict the loss gradient of the strong model. Then, the strong model&#x27;s output is updated by subtracting the predicted gradient, similar to gradient descent</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gradient-boost-过程">gradient boost 过程<a href="#gradient-boost-过程" class="hash-link" aria-label="Direct link to gradient boost 过程" title="Direct link to gradient boost 过程">​</a></h2>
<p>Suppose, we were trying to predict the price of a house given their age, square footage and location.</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302210359.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-calculate-the-average-of-the-target-label">Step 1: Calculate the average of the target label<a href="#step-1-calculate-the-average-of-the-target-label" class="hash-link" aria-label="Direct link to Step 1: Calculate the average of the target label" title="Direct link to Step 1: Calculate the average of the target label">​</a></h3>
<p>When tackling regression problems, we start with a leaf that is the average value of the variable we want to predict. This leaf will be used as a baseline to approach the correct solution in the proceeding steps.</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302210774.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-calculate-the-residuals">Step 2: Calculate the residuals<a href="#step-2-calculate-the-residuals" class="hash-link" aria-label="Direct link to Step 2: Calculate the residuals" title="Direct link to Step 2: Calculate the residuals">​</a></h3>
<p>For every sample, we calculate the residual with the proceeding formula.</p>
<blockquote>
<p>residual = actual value – predicted value</p>
</blockquote>
<p>In our example, the predicted value is the equal to the mean calculated in the previous step and the actual value can be found in the price column of each sample. After computing the residuals, we get the following table.</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302211021.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-construct-a-decision-tree">Step 3: Construct a decision tree<a href="#step-3-construct-a-decision-tree" class="hash-link" aria-label="Direct link to Step 3: Construct a decision tree" title="Direct link to Step 3: Construct a decision tree">​</a></h3>
<p>Next, we build a tree with the goal of predicting the residuals. In other words, every leaf will contain a prediction as to the value of the residual (not the desired label).</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302213623.png" alt="" class="img_ev3q"></p>
<p>In the event there are more residuals than leaves, some residuals will end up inside the same leaf. When this happens, we compute their average and place that inside the leaf.</p>
<p>Thus, the tree becomes:</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302213246.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-predict-the-target-label-using-all-of-the-trees-within-the-ensemble">Step 4: Predict the target label using all of the trees within the ensemble<a href="#step-4-predict-the-target-label-using-all-of-the-trees-within-the-ensemble" class="hash-link" aria-label="Direct link to Step 4: Predict the target label using all of the trees within the ensemble" title="Direct link to Step 4: Predict the target label using all of the trees within the ensemble">​</a></h3>
<p>Each sample passes through the decision nodes of the newly formed tree until it reaches a given lead. The residual in said leaf is used to predict the house price.</p>
<p>例如，对左下角的这个node，就是这样算：</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302220441.png" alt="" class="img_ev3q"></p>
<p>或者中间的这个node：</p>
<p>predicted_price = 688 + 0.1 * (-208) = 667.2</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-compute-the-new-residuals">Step 5: Compute the new residuals<a href="#step-5-compute-the-new-residuals" class="hash-link" aria-label="Direct link to Step 5: Compute the new residuals" title="Direct link to Step 5: Compute the new residuals">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302301353.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-6-repeat-steps-3---5-until-the-number-of-iterations-matches-the-number-specified-by-the-hyperparameter-ie--iterations">Step 6: Repeat steps 3 - 5 until the number of iterations matches the number specified by the hyperparameter (i.e., # iterations)<a href="#step-6-repeat-steps-3---5-until-the-number-of-iterations-matches-the-number-specified-by-the-hyperparameter-ie--iterations" class="hash-link" aria-label="Direct link to Step 6: Repeat steps 3 - 5 until the number of iterations matches the number specified by the hyperparameter (i.e., # iterations)" title="Direct link to Step 6: Repeat steps 3 - 5 until the number of iterations matches the number specified by the hyperparameter (i.e., # iterations)">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302223105.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-7-once-trained-use-all-of-the-trees-in-the-ensemble-to-make-a-final-prediction-as-to-the-value-of-the-target-variable">Step 7: Once trained, use all of the trees in the ensemble to make a final prediction as to the value of the target variable<a href="#step-7-once-trained-use-all-of-the-trees-in-the-ensemble-to-make-a-final-prediction-as-to-the-value-of-the-target-variable" class="hash-link" aria-label="Direct link to Step 7: Once trained, use all of the trees in the ensemble to make a final prediction as to the value of the target variable" title="Direct link to Step 7: Once trained, use all of the trees in the ensemble to make a final prediction as to the value of the target variable">​</a></h3>
<p>The final prediction will be equal to the mean we computed in the first step, plus all of the residuals predicted by the trees that make up the forest multiplied by the learning rate.</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/emmableu/image/master/202209302223078.png" alt="" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="xgboost-step-by-step">XGBoost step by step<a href="#xgboost-step-by-step" class="hash-link" aria-label="Direct link to XGBoost step by step" title="Direct link to XGBoost step by step">​</a></h2>
<p>Let’s start with our training dataset which consists of five people. We recorded their ages, whether or not they have a master’s degree, and their salary (in thousands). Our goal is to predict <em>Salary</em> using the XGBoost Algorithm.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*_KUzdQTdTUfjPposrAxSfQ.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-make-an-initial-prediction-and-calculate-residuals">Step 1: Make an Initial Prediction and Calculate Residuals<a href="#step-1-make-an-initial-prediction-and-calculate-residuals" class="hash-link" aria-label="Direct link to Step 1: Make an Initial Prediction and Calculate Residuals" title="Direct link to Step 1: Make an Initial Prediction and Calculate Residuals">​</a></h3>
<p><a href="https://towardsdatascience.com/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb" target="_blank" rel="noopener noreferrer">source</a></p>
<p>This prediction can be anything. But let’s assume our initial prediction is the average value of the variables we want to predict.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*GjxcMQDQQqU-UfgfvBeb1A.png" alt="" class="img_ev3q"></p>
<p>We can calculate residuals using the following formula:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*AEwarDLHuDQZmMlB-2VDpw.png" alt="" class="img_ev3q"></p>
<p>Here, our Observed Values are the values in the <em>Salary</em> column and all Predicted Values are equal to 70 because that is what we chose our initial prediction to be.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*D5eCwr_TYcwuDP8NBOAOsg.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-build-an-xgboost-tree">Step 2: Build an XGBoost Tree<a href="#step-2-build-an-xgboost-tree" class="hash-link" aria-label="Direct link to Step 2: Build an XGBoost Tree" title="Direct link to Step 2: Build an XGBoost Tree">​</a></h3>
<p>Each tree starts with a single leaf and all the residuals go into that leaf.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1036/1*yYq5mmVkYk1Lwl_aspUq6A.png" alt="" class="img_ev3q"></p>
<p>Now we need to calculate something called a <strong>Similarity Score</strong> of this leaf.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*ddxctrOTVbqPhppkcxCzFw.png" alt="" class="img_ev3q"></p>
<p>λ (lambda) is a regularization parameter that reduces the prediction’s sensitivity to individual observations and prevents the overfitting of data (this is when a model fits exactly against the training dataset). The default value of λ is 1 so we will let λ = 1 in this example.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*3bc39LtxpRTqQ0kivyrQlw.png" alt="" class="img_ev3q"></p>
<p>Now we should see if we can do a better job clustering the residuals if we split them into two groups using thresholds based on our predictors — <em>Age</em> and <em>Master’s Degree?.</em> Splitting the <em>Residuals</em> basically means that we are adding branches to our tree.</p>
<p>First, let’s try splitting the leaf using <em>Master’s Degree</em><strong>?</strong></p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*iofkdqDDgFDhOHRxjmjz5w.png" alt="" class="img_ev3q"></p>
<p>And then calculate the <strong>Similarity Scores</strong> for the left and right leaves of the above split:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*rNlX9qaQqc8xGSUXvkwkKg.png" alt="" class="img_ev3q"></p>
<p>Now we need to quantify how much better the leaves cluster similar <em>Residuals</em> than the root does. We can do this by calculating the <strong>Gain</strong> of splitting the <em>Residuals</em> into two groups. If the <strong>Gain</strong> is positive, then it’s a good idea to split, otherwise, it is not.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1222/0*rIeNeoesHLox_5p8.png" alt="" class="img_ev3q"></p>
<p>Then we compare this <strong>Gain</strong> to those of the splits in <em>Age</em>. Since <em>Age</em> is a continuous variable, the process to find the different splits is a little more involved. First, we arrange the rows of our dataset according to the ascending order of <em>Age</em>. Then we calculate the average values of the adjacent values in <em>Age</em>.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/550/0*JruyoPHXdM9LxPPW" alt="" class="img_ev3q"></p>
<p>Now we split the <em>Residuals</em> using the four averages as thresholds and calculate <strong>Gain</strong> for each of the splits. The first split uses <em>Age &lt; 23.5</em>:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1222/1*4285F3yPyqgvkDf0a3JtJA.png" alt="" class="img_ev3q"></p>
<p>For this split, we find the <strong>Similarity Score</strong> and <strong>Gain</strong> the same way we did for <em>Master’s Degree?</em></p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*QG-8M5rLc_WFo293kdn32Q.png" alt="" class="img_ev3q"></p>
<p>Do the same thing for the rest of the <em>Age</em> splits:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*HrG-WfVT9O5ve7Yso3dL9g.png" alt="" class="img_ev3q"></p>
<p>Out of the one <em>Mater’s Degree?</em> split and four <em>Age</em> splits, the <em>Master’s Degree</em> split has the greatest <strong>Gain</strong> value, so we’ll use that as our initial split. Now we can add more branches to the tree by splitting our <em>Master’s Degree?</em> leaves again using the same process described above. But, only this time, we use the initial <em>Master’s Degree?</em> leaves as our root nodes and try splitting them by getting the greatest <strong>Gain</strong> value that is greater than 0.</p>
<p>Let’s start with the left node. For this node, we only consider the observations that have the value ‘Yes’ in <em>Master’s Degree?</em> because only those observations land in the left node.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*ZaDD16j0hBb3kIp4iOgPcA.png" alt="" class="img_ev3q"></p>
<p>So we calculate the <strong>Gain</strong> of the <em>Age</em> splits using the same process as before, but this time using the <em>Residuals</em> in the highlighted rows only.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*ArdKYPYzu9oRcJCsoOgOKQ.png" alt="" class="img_ev3q"></p>
<p>Since only <em>Age &lt; 25</em> gives us a positive <strong>Gain</strong>, we split the left node using this threshold. Moving onto our right node, we only look at values with ‘No’ values in <em>Master’s Degree?</em></p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*wT0cScVpEqPSa4OAJSuJLg.png" alt="" class="img_ev3q"></p>
<p>We only have two observations in our right node, so the only split possible is <em>Age &lt; 24.5</em> because that is the average of the two <em>Age</em> values in the highlighted rows.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*I4xa7BIP1YcZOyl_K1eBEg.png" alt="" class="img_ev3q"></p>
<p>The <strong>Gain</strong> of this split is positive, so our final tree is:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1298/1*LOq80DzUJSo3ndw1P9PoAQ.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-prune-the-tree"><strong><em>Step 3: Prune the Tree</em></strong><a href="#step-3-prune-the-tree" class="hash-link" aria-label="Direct link to step-3-prune-the-tree" title="Direct link to step-3-prune-the-tree">​</a></h3>
<p>Pruning is another way we can avoid overfitting the data. To do this we start from the bottom of our tree and work our way up to see if a split is valid or not. To establish validity, we use γ (gamma). If <strong>Gain —</strong> γ is positive then we keep the split, otherwise, we remove it. The default value of γ is 0, but for illustrative purposes, let’s set our γ to 50. From previous calculations we know the <strong>Gain</strong> values:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*I1ukSNGxqbB1tAHZBqw7qA.png" alt="" class="img_ev3q"></p>
<p>Since <strong>Gain —</strong> γ is positive for all splits except that of <em>Age &lt; 24.5</em>, we can remove that branch. So the resulting tree is:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1168/1*n0b6WmYcJXw4UCpy0DCGRA.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-calculate-the-output-values-of-leaves"><strong><em>Step 4: Calculate the Output Values of Leaves</em></strong><a href="#step-4-calculate-the-output-values-of-leaves" class="hash-link" aria-label="Direct link to step-4-calculate-the-output-values-of-leaves" title="Direct link to step-4-calculate-the-output-values-of-leaves">​</a></h3>
<p>We are almost there! All we have to do now is calculate a single value in our leaf nodes because we can not have a leaf node giving us multiple outputs.</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/0*XmYMrpfsKZF6XWOb" alt="" class="img_ev3q"></p>
<p>This is similar to the formula to calculate <strong>Similarity Score</strong> except we are not squaring the <em>Residuals</em>. Using the formula and λ = 1, <em><em>drum roll</em></em> our final tree is:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*FSIFRB1N8bR52vixSWR19A.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-make-new-predictions"><strong><em>Step 5: Make New Predictions</em></strong><a href="#step-5-make-new-predictions" class="hash-link" aria-label="Direct link to step-5-make-new-predictions" title="Direct link to step-5-make-new-predictions">​</a></h3>
<p>Now that all that hard model building is behind us, we come to the exciting part and see how much our predictions improve using our new model. We can make predictions using this formula:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*tIEzTeLj_yHOIQWVVqPQ9w.png" alt="" class="img_ev3q"></p>
<p>The XGBoost Learning Rate is ɛ (eta) and the default value is 0.3. So the predicted value of our first observation will be:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*EYwsm84uQB4-WNQfezfwCA.png" alt="" class="img_ev3q"></p>
<p>Similarly, we can calculate the rest of the predicted values:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*7tDf4x_6I-WehIG2yI7BMw.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-6-calculate-residuals-using-the-new-predictions"><strong><em>Step 6: Calculate Residuals Using the New Predictions</em></strong><a href="#step-6-calculate-residuals-using-the-new-predictions" class="hash-link" aria-label="Direct link to step-6-calculate-residuals-using-the-new-predictions" title="Direct link to step-6-calculate-residuals-using-the-new-predictions">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*tIqXoaKD_41QeCBfe2xxqQ.png" alt="" class="img_ev3q"></p>
<p>We see that the new <em>Residuals</em> are smaller than the ones before, this indicates that we’ve taken a small step in the right direction. As we repeat this process, our <em>Residuals</em> will get smaller and smaller indicating that our predicted values are getting closer to the observed values.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-7-repeat-steps-26"><strong><em>Step 7: Repeat Steps 2–6</em></strong><a href="#step-7-repeat-steps-26" class="hash-link" aria-label="Direct link to step-7-repeat-steps-26" title="Direct link to step-7-repeat-steps-26">​</a></h3>
<p>Now we just repeat the same process over and over again, building a new tree, making predictions, and calculating <em>Residuals</em> at each iteration. We do this until the <em>Residuals</em> are super small or we reached the maximum number of iterations we set for our algorithm. If the tree we built at each iteration is indicated by Tᵢ, where <em>i</em> is the current iteration, then the formula to calculate predictions is:</p>
<p><img decoding="async" loading="lazy" src="https://miro.medium.com/max/1400/1*MiHVOymdS80S8o_uv96Ubw.png" alt="" class="img_ev3q"></p>
<p>And that’s it. Thanks for reading and good luck with the rest of your algorithmic journey!</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/emmableu/notes/edit/main/docs/05. ML General/39.Gradient Boost 细节.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/notes/docs/p/75d0bf4d-fcc2-4e72-b273-4e862d8898f8"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">GMM - Gaussian Mixed Models</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/notes/docs/p/a5f44b92-03c1-475e-a773-76c53542b1ad"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">T-SNE or tSNE or tsne</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#definition" class="table-of-contents__link toc-highlight">Definition</a></li><li><a href="#gradient-boost-过程" class="table-of-contents__link toc-highlight">gradient boost 过程</a><ul><li><a href="#step-1-calculate-the-average-of-the-target-label" class="table-of-contents__link toc-highlight">Step 1: Calculate the average of the target label</a></li><li><a href="#step-2-calculate-the-residuals" class="table-of-contents__link toc-highlight">Step 2: Calculate the residuals</a></li><li><a href="#step-3-construct-a-decision-tree" class="table-of-contents__link toc-highlight">Step 3: Construct a decision tree</a></li><li><a href="#step-4-predict-the-target-label-using-all-of-the-trees-within-the-ensemble" class="table-of-contents__link toc-highlight">Step 4: Predict the target label using all of the trees within the ensemble</a></li><li><a href="#step-5-compute-the-new-residuals" class="table-of-contents__link toc-highlight">Step 5: Compute the new residuals</a></li><li><a href="#step-6-repeat-steps-3---5-until-the-number-of-iterations-matches-the-number-specified-by-the-hyperparameter-ie--iterations" class="table-of-contents__link toc-highlight">Step 6: Repeat steps 3 - 5 until the number of iterations matches the number specified by the hyperparameter (i.e., # iterations)</a></li><li><a href="#step-7-once-trained-use-all-of-the-trees-in-the-ensemble-to-make-a-final-prediction-as-to-the-value-of-the-target-variable" class="table-of-contents__link toc-highlight">Step 7: Once trained, use all of the trees in the ensemble to make a final prediction as to the value of the target variable</a></li></ul></li><li><a href="#xgboost-step-by-step" class="table-of-contents__link toc-highlight">XGBoost step by step</a><ul><li><a href="#step-1-make-an-initial-prediction-and-calculate-residuals" class="table-of-contents__link toc-highlight">Step 1: Make an Initial Prediction and Calculate Residuals</a></li><li><a href="#step-2-build-an-xgboost-tree" class="table-of-contents__link toc-highlight">Step 2: Build an XGBoost Tree</a></li><li><a href="#step-3-prune-the-tree" class="table-of-contents__link toc-highlight"><strong><em>Step 3: Prune the Tree</em></strong></a></li><li><a href="#step-4-calculate-the-output-values-of-leaves" class="table-of-contents__link toc-highlight"><strong><em>Step 4: Calculate the Output Values of Leaves</em></strong></a></li><li><a href="#step-5-make-new-predictions" class="table-of-contents__link toc-highlight"><strong><em>Step 5: Make New Predictions</em></strong></a></li><li><a href="#step-6-calculate-residuals-using-the-new-predictions" class="table-of-contents__link toc-highlight"><strong><em>Step 6: Calculate Residuals Using the New Predictions</em></strong></a></li><li><a href="#step-7-repeat-steps-26" class="table-of-contents__link toc-highlight"><strong><em>Step 7: Repeat Steps 2–6</em></strong></a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes/docs/intro">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/notes/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/emmableu/notes" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2026 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>